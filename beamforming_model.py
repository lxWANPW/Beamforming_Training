import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import scipy.io as sio
import h5py
import os
import glob
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from torch.nn import TransformerEncoder, TransformerEncoderLayer
import math
from tqdm import tqdm
import warnings

class BeamformingDataset(Dataset):
    """å¤©çº¿é˜µåˆ—ä¿¡é“æ•°æ®é›†"""
    def __init__(self, channel_folder, angle_folder, transform=None):
        self.channel_folder = channel_folder
        self.angle_folder = angle_folder
        self.transform = transform
        
        # è·å–ä¿¡é“æ•°æ®æ–‡ä»¶åˆ—è¡¨
        self.channel_files = sorted(glob.glob(os.path.join(channel_folder, '*.mat')))
        
        # åŠ è½½è§’åº¦æ•°æ®
        angle_files = glob.glob(os.path.join(angle_folder, '*.mat'))
        if len(angle_files) > 0:
            try:
                # å°è¯•ä½¿ç”¨ h5py è¯»å–
                with h5py.File(angle_files[0], 'r') as f:
                    all_theta = np.array(f['all_theta'])  # (50, 1000)
                    all_phi = np.array(f['all_phi'])      # (50, 1000)
                    
                    # è½¬ç½®ä»¥åŒ¹é…é¢„æœŸå½¢çŠ¶ [num_samples, num_time_samples]
                    self.theta_array = all_theta.T  # (1000, 50)
                    self.phi_array = all_phi.T      # (1000, 50)
                    
                    self.num_samples = int(np.array(f['num_samples'])[0, 0])
                    self.num_time_samples = int(np.array(f['num_time_samples'])[0, 0])
                    
                    print(f"è§’åº¦æ•°æ®å½¢çŠ¶: theta={self.theta_array.shape}, phi={self.phi_array.shape}")
                    print(f"ä¿¡é“æ•°æ®æ–‡ä»¶æ•°é‡: {len(self.channel_files)}")
                    
            except Exception as e:
                print(f"h5py è¯»å–å¤±è´¥: {e}")
                # å¦‚æœ h5py å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ scipy.io
                try:
                    angle_data = sio.loadmat(angle_files[0])
                    self.theta_array = angle_data['theta_array']  # [num_samples, num_time_samples]
                    self.phi_array = angle_data['phi_array']
                    self.num_samples = angle_data['num_samples'][0][0]
                    self.num_time_samples = angle_data['num_time_samples'][0][0]
                except Exception as e2:
                    print(f"scipy.io è¯»å–ä¹Ÿå¤±è´¥: {e2}")
                    raise e2
        
        # ç¡®ä¿è§’åº¦æ•°æ®å’Œä¿¡é“æ•°æ®çš„æ ·æœ¬æ•°é‡åŒ¹é…
        # ä½¿ç”¨è¾ƒå°çš„æ•°é‡ä½œä¸ºå®é™…çš„æ•°æ®é›†å¤§å°
        self.actual_num_samples = min(len(self.channel_files), self.theta_array.shape[0])
        print(f"å®é™…ä½¿ç”¨çš„æ ·æœ¬æ•°é‡: {self.actual_num_samples}")
        
    def __len__(self):
        return self.actual_num_samples
    
    def __getitem__(self, idx):
        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if idx >= self.actual_num_samples:
            raise IndexError(f"ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ {self.actual_num_samples}")
            
        # åŠ è½½ä¿¡é“æ•°æ®
        try:
            # å°è¯•ä½¿ç”¨ h5py è¯»å–
            with h5py.File(self.channel_files[idx], 'r') as f:
                H_real = np.array(f['H_real'])  # (50, 256, 256)
                H_imag = np.array(f['H_imag'])  # (50, 256, 256)
                
                # è½¬ç½®ä»¥åŒ¹é…é¢„æœŸæ ¼å¼ [256, 256, 50]
                H_real = H_real.transpose(1, 2, 0)  # (256, 256, 50)
                H_imag = H_imag.transpose(1, 2, 0)  # (256, 256, 50)
                
        except Exception as e:
            print(f"h5py è¯»å–ä¿¡é“æ•°æ®å¤±è´¥: {e}")
            # å¦‚æœ h5py å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ scipy.io
            try:
                channel_data = sio.loadmat(self.channel_files[idx])
                H_real = channel_data['H_real']  # [256, 256, 50]
                H_imag = channel_data['H_imag']
            except Exception as e2:
                print(f"scipy.io è¯»å–ä¿¡é“æ•°æ®ä¹Ÿå¤±è´¥: {e2}")
                raise e2
        
        # ç»„åˆå®éƒ¨å’Œè™šéƒ¨
        H_complex = H_real + 1j * H_imag
        
        # æ•°æ®å½’ä¸€åŒ–å¤„ç†
        H_real_norm = (H_real - np.mean(H_real)) / (np.std(H_real) + 1e-8)
        H_imag_norm = (H_imag - np.mean(H_imag)) / (np.std(H_imag) + 1e-8)
        
        # è½¬æ¢ä¸ºPyTorch tensor
        H_input = np.stack([H_real_norm, H_imag_norm], axis=0)  # [2, 256, 256, 50]
        H_input = torch.FloatTensor(H_input)
        
        # è§’åº¦æ ‡ç­¾å½’ä¸€åŒ–ï¼ˆè½¬æ¢ä¸ºå¼§åº¦å¹¶å½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
        theta_norm = (self.theta_array[idx] * np.pi / 180) / (np.pi/2)  # å½’ä¸€åŒ–åˆ°[-1,1]
        phi_norm = (self.phi_array[idx] * np.pi / 180) / np.pi  # å½’ä¸€åŒ–åˆ°[-1,1]
        
        theta_label = torch.FloatTensor(theta_norm)  # [50]
        phi_label = torch.FloatTensor(phi_norm)      # [50]
        
        return H_input, theta_label, phi_label, H_complex

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
        
    def forward(self, x):
        return x + self.pe[:x.size(0), :]

class MultiTaskBeamformingTransformer(nn.Module):
    """å¤šä»»åŠ¡æ³¢æŸæˆå½¢Transformeræ¨¡å‹"""
    def __init__(self, input_dim=256*256*2, d_model=512, nhead=8, num_layers=6, 
                 num_subarrays=16, dropout=0.1):
        super(MultiTaskBeamformingTransformer, self).__init__()
        
        self.d_model = d_model
        self.num_subarrays = num_subarrays
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_dim, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model)
        
        # Transformerç¼–ç å™¨
        encoder_layers = TransformerEncoderLayer(
            d_model=d_model, 
            nhead=nhead, 
            dim_feedforward=2048,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)
        
        # ä»»åŠ¡ç‰¹å®šå¤´éƒ¨
        # 1. è§’åº¦é¢„æµ‹å¤´
        self.angle_head = nn.Sequential(
            nn.Linear(d_model, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 2)  # theta, phi
        )
        
        # 2. æ³¢æŸæˆå½¢æƒé‡å¤´
        self.beamforming_head = nn.Sequential(
            nn.Linear(d_model, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 256*2)  # å¤æ•°æƒé‡çš„å®éƒ¨å’Œè™šéƒ¨
        )
        
        # 3. å­é˜µåˆ—åˆ’åˆ†å¤´
        self.subarray_head = nn.Sequential(
            nn.Linear(d_model, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, num_subarrays)  # æ¯ä¸ªå¤©çº¿å…ƒç´ å±äºå“ªä¸ªå­é˜µåˆ—
        )
        
        # 4. æ³¢æŸå›¾è´¨é‡é¢„æµ‹å¤´
        self.beam_quality_head = nn.Sequential(
            nn.Linear(d_model, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 3)  # ä¸»ç“£å®½åº¦, æ—ç“£æŠ‘åˆ¶é‡, SNRå¢ç›Š
        )
        
    def forward(self, x):
        batch_size, channels, height, width, time_steps = x.shape
        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        
        # é‡å¡‘è¾“å…¥ [batch, time_steps, features]
        x = x.permute(0, 4, 1, 2, 3)  # [batch, time_steps, channels, height, width]
        x = x.reshape(batch_size, time_steps, -1)  # [batch, time_steps, channels*height*width]
        print(f"é‡å¡‘åå½¢çŠ¶: {x.shape}")
        
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x) * math.sqrt(self.d_model)
        
        # ä½ç½®ç¼–ç 
        x = x.transpose(0, 1)  # [time_steps, batch, d_model]
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)  # [batch, time_steps, d_model]
        
        # Transformerç¼–ç 
        encoded = self.transformer_encoder(x)  # [batch, time_steps, d_model]
        
        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè¿›è¡Œé¢„æµ‹
        last_output = encoded[:, -1, :]  # [batch, d_model]
        
        # å¤šä»»åŠ¡è¾“å‡º
        angles = self.angle_head(last_output)  # [batch, 2]
        beamforming_weights = self.beamforming_head(last_output)  # [batch, 512]
        subarray_assignment = self.subarray_head(last_output)  # [batch, num_subarrays]
        beam_quality = self.beam_quality_head(last_output)  # [batch, 3]
        
        return {
            'angles': angles,
            'beamforming_weights': beamforming_weights,
            'subarray_assignment': subarray_assignment,
            'beam_quality': beam_quality
        }

def calculate_beam_pattern(weights, angles, antenna_positions):
    """è®¡ç®—æ³¢æŸå›¾"""
    theta_range = np.linspace(0, 90, 91)
    phi_range = np.linspace(0, 360, 361)
    
    beam_pattern = np.zeros((len(theta_range), len(phi_range)))
    
    for i, theta in enumerate(theta_range):
        for j, phi in enumerate(phi_range):
            # è®¡ç®—å¯¼å‘çŸ¢é‡
            az = phi * np.pi / 180
            el = theta * np.pi / 180
            k = (2*np.pi/0.0857) * np.array([np.cos(el)*np.cos(az), np.cos(el)*np.sin(az)])
            
            steering_vector = np.exp(1j * (antenna_positions @ k))
            
            # è®¡ç®—æ³¢æŸå“åº”
            response = np.abs(np.vdot(weights, steering_vector))**2
            beam_pattern[i, j] = response
    
    return beam_pattern, theta_range, phi_range

def compute_beam_metrics(beam_pattern, target_theta, target_phi):
    """è®¡ç®—æ³¢æŸå›¾æ€§èƒ½æŒ‡æ ‡"""
    # ä¸»ç“£å®½åº¦è®¡ç®—ï¼ˆ3dBå¸¦å®½ï¼‰
    max_gain = np.max(beam_pattern)
    half_power = max_gain / 2
    
    # æ‰¾åˆ°æœ€å¤§å€¼ä½ç½®
    max_idx = np.unravel_index(np.argmax(beam_pattern), beam_pattern.shape)
    
    # è®¡ç®—ä¸»ç“£å®½åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    main_lobe_width = np.sum(beam_pattern > half_power) * (360 / beam_pattern.shape[1])
    
    # æ—ç“£æŠ‘åˆ¶é‡
    # æ’é™¤ä¸»ç“£åŒºåŸŸ
    main_lobe_mask = np.zeros_like(beam_pattern)
    theta_idx, phi_idx = max_idx
    main_lobe_mask[max(0, theta_idx-5):min(beam_pattern.shape[0], theta_idx+6),
                   max(0, phi_idx-10):min(beam_pattern.shape[1], phi_idx+11)] = 1
    
    side_lobe_region = beam_pattern * (1 - main_lobe_mask)
    max_side_lobe = np.max(side_lobe_region)
    side_lobe_suppression = 10 * np.log10(max_gain / (max_side_lobe + 1e-10))
    
    return main_lobe_width, side_lobe_suppression

def multi_task_loss(predictions, targets, alpha=1.0, beta=0.1, gamma=0.01, delta=0.01):
    """å¤šä»»åŠ¡æŸå¤±å‡½æ•°"""
    pred_angles = predictions['angles']
    pred_beamforming = predictions['beamforming_weights']
    pred_subarray = predictions['subarray_assignment']
    pred_beam_quality = predictions['beam_quality']
    
    target_theta, target_phi, H_complex = targets
    
    # 1. è§’åº¦é¢„æµ‹æŸå¤±ï¼ˆä½¿ç”¨å¹³æ»‘L1æŸå¤±ï¼Œæ›´ç¨³å®šï¼‰
    angle_loss = F.smooth_l1_loss(pred_angles[:, 0], target_theta[:, -1]) + \
                 F.smooth_l1_loss(pred_angles[:, 1], target_phi[:, -1])
    
    # 2. æ³¢æŸæˆå½¢æŸå¤±ï¼ˆåŸºäºSNRæœ€å¤§åŒ–ï¼Œæ·»åŠ æ•°å€¼ç¨³å®šæ€§ï¼‰
    batch_size = pred_beamforming.shape[0]
    beamforming_loss = 0
    
    for i in range(batch_size):
        try:
            # é‡æ„å¤æ•°æƒé‡
            weights_real = pred_beamforming[i, :256]
            weights_imag = pred_beamforming[i, 256:]
            weights = weights_real + 1j * weights_imag
            
            # æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
            if torch.any(torch.isnan(weights)) or torch.any(torch.isinf(weights)):
                beamforming_loss += 1.0  # æƒ©ç½šä¸ç¨³å®šçš„æƒé‡
                continue
                
            weights = weights / (torch.norm(weights) + 1e-8)  # å®‰å…¨å½’ä¸€åŒ–
            
            # è®¡ç®—è¾“å‡ºSNRï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¤æ‚è®¡ç®—ï¼‰
            H_i = H_complex[i][:, :, -1]  # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥
            H_i = H_i.to(weights.dtype)
            
            # å®‰å…¨çš„SNRè®¡ç®—
            signal_power = torch.abs(torch.vdot(weights, H_i.flatten()))**2
            noise_power = torch.norm(weights)**2 + 1e-8
            snr = signal_power / noise_power
            
            # ä½¿ç”¨log1pè€Œä¸æ˜¯logï¼Œé¿å…æ•°å€¼é—®é¢˜
            beamforming_loss += -torch.log1p(snr)
            
        except Exception as e:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œæ·»åŠ ä¸€ä¸ªæƒ©ç½šé¡¹
            beamforming_loss += 1.0
    
    beamforming_loss /= batch_size
    
    # 3. å­é˜µåˆ—åˆ’åˆ†æŸå¤±ï¼ˆæ­£åˆ™åŒ–é¡¹ï¼‰
    subarray_loss = torch.var(torch.sum(F.softmax(pred_subarray, dim=-1), dim=0))
    
    # 4. æ³¢æŸè´¨é‡æŸå¤±ï¼ˆè¾…åŠ©ç›‘ç£ï¼‰
    beam_quality_loss = torch.mean(pred_beam_quality**2)  # ç®€åŒ–çš„æ­£åˆ™åŒ–é¡¹
    
    # ç¡®ä¿æ‰€æœ‰æŸå¤±éƒ½æ˜¯æœ‰é™çš„
    angle_loss = torch.clamp(angle_loss, 0, 100)
    beamforming_loss = torch.clamp(beamforming_loss, 0, 100)
    subarray_loss = torch.clamp(subarray_loss, 0, 10)
    beam_quality_loss = torch.clamp(beam_quality_loss, 0, 10)
    
    total_loss = alpha * angle_loss + beta * beamforming_loss + \
                 gamma * subarray_loss + delta * beam_quality_loss
    
    return total_loss, angle_loss, beamforming_loss, subarray_loss, beam_quality_loss

def train_model(model, train_loader, val_loader, num_epochs=100, lr=1e-5, device='cuda'):
    """è®­ç»ƒå‡½æ•°"""
    model.to(device)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
    
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 15
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œå­¦ä¹ ç‡: {lr}")
    
    # è®­ç»ƒè¿›åº¦æ¡
    epoch_progress = tqdm(range(num_epochs), desc="è®­ç»ƒè¿›åº¦", unit="epoch")
    
    for epoch in epoch_progress:
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_epoch = 0
        train_metrics = {'angle': 0, 'beam': 0, 'sub': 0, 'quality': 0}
        
        # æ‰¹æ¬¡è¿›åº¦æ¡
        batch_progress = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}", 
                            leave=False, unit="batch")
        
        for batch_idx, (H_input, theta_label, phi_label, H_complex) in enumerate(batch_progress):
            try:
                H_input = H_input.to(device)
                theta_label = theta_label.to(device)
                phi_label = phi_label.to(device)
                H_complex = H_complex.to(device)
                
                optimizer.zero_grad()
                
                # å‰å‘ä¼ æ’­
                predictions = model(H_input)
                
                # è®¡ç®—æŸå¤±
                loss, angle_loss, beam_loss, sub_loss, quality_loss = multi_task_loss(
                    predictions, (theta_label, phi_label, H_complex)
                )
                
                # æ£€æŸ¥æŸå¤±æ˜¯å¦æœ‰æ•ˆ
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"è­¦å‘Š: åœ¨Epoch {epoch}, Batch {batch_idx} æ£€æµ‹åˆ°æ— æ•ˆæŸå¤±ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡")
                    continue
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ¢¯åº¦è£å‰ªï¼ˆæ›´ä¿å®ˆçš„è®¾ç½®ï¼‰
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)
                
                optimizer.step()
                
                train_loss_epoch += loss.item()
                train_metrics['angle'] += angle_loss.item()
                train_metrics['beam'] += beam_loss.item()
                train_metrics['sub'] += sub_loss.item()
                train_metrics['quality'] += quality_loss.item()
                
                # æ›´æ–°æ‰¹æ¬¡è¿›åº¦æ¡
                batch_progress.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Angle': f'{angle_loss.item():.4f}',
                    'Beam': f'{beam_loss.item():.4f}'
                })
                
            except Exception as e:
                print(f"è®­ç»ƒæ‰¹æ¬¡é”™è¯¯: {e}")
                continue
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_epoch = 0
        val_metrics = {'angle': 0, 'beam': 0, 'sub': 0, 'quality': 0}
        
        with torch.no_grad():
            for H_input, theta_label, phi_label, H_complex in val_loader:
                try:
                    H_input = H_input.to(device)
                    theta_label = theta_label.to(device)
                    phi_label = phi_label.to(device)
                    H_complex = H_complex.to(device)
                    
                    predictions = model(H_input)
                    loss, angle_loss, beam_loss, sub_loss, quality_loss = multi_task_loss(
                        predictions, (theta_label, phi_label, H_complex)
                    )
                    
                    if not (torch.isnan(loss) or torch.isinf(loss)):
                        val_loss_epoch += loss.item()
                        val_metrics['angle'] += angle_loss.item()
                        val_metrics['beam'] += beam_loss.item()
                        val_metrics['sub'] += sub_loss.item()
                        val_metrics['quality'] += quality_loss.item()
                        
                except Exception as e:
                    print(f"éªŒè¯æ‰¹æ¬¡é”™è¯¯: {e}")
                    continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        train_loss_avg = train_loss_epoch / len(train_loader) if len(train_loader) > 0 else float('inf')
        val_loss_avg = val_loss_epoch / len(val_loader) if len(val_loader) > 0 else float('inf')
        
        train_losses.append(train_loss_avg)
        val_losses.append(val_loss_avg)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss_avg)
        
        # æ›´æ–°epochè¿›åº¦æ¡
        epoch_progress.set_postfix({
            'Train Loss': f'{train_loss_avg:.4f}',
            'Val Loss': f'{val_loss_avg:.4f}',
            'LR': f'{optimizer.param_groups[0]["lr"]:.2e}'
        })
        
        # æ—©åœæœºåˆ¶
        if val_loss_avg < best_val_loss:
            best_val_loss = val_loss_avg
            patience_counter = 0
            torch.save(model.state_dict(), 'best_beamforming_model.pth')
            tqdm.write(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Loss: {val_loss_avg:.4f})")
        else:
            patience_counter += 1
            
        if patience_counter >= early_stop_patience:
            tqdm.write(f"æ—©åœè§¦å‘ï¼åœ¨epoch {epoch+1}åœæ­¢è®­ç»ƒ")
            break
        
        # è¯¦ç»†æ—¥å¿—ï¼ˆæ¯5ä¸ªepochï¼‰
        if (epoch + 1) % 5 == 0:
            tqdm.write(f"Epoch {epoch+1}: Train={train_loss_avg:.4f}, Val={val_loss_avg:.4f}, "
                      f"Angle={train_metrics['angle']/len(train_loader):.4f}, "
                      f"Beam={train_metrics['beam']/len(train_loader):.4f}")
    
    return train_losses, val_losses

def test_model(model, test_loader, device='cuda'):
    """æµ‹è¯•å‡½æ•°"""
    model.to(device)
    model.eval()
    
    all_predictions = []
    all_targets = []
    angle_errors = []
    
    antenna_positions = np.array([[i, j] for i in range(16) for j in range(16)]) * 0.0428
    
    test_progress = tqdm(test_loader, desc="æµ‹è¯•è¿›åº¦", unit="batch")
    
    with torch.no_grad():
        for H_input, theta_label, phi_label, H_complex in test_progress:
            try:
                H_input = H_input.to(device)
                theta_label = theta_label.to(device)
                phi_label = phi_label.to(device)
                
                # é¢„æµ‹
                predictions = model(H_input)
                
                # ç§»åŠ¨åˆ°CPUè¿›è¡Œåå¤„ç†
                pred_angles = predictions['angles'].cpu().numpy()
                pred_beamforming = predictions['beamforming_weights'].cpu().numpy()
                pred_subarray = predictions['subarray_assignment'].cpu().numpy()
                
                # å°†å½’ä¸€åŒ–çš„è§’åº¦è½¬æ¢å›åº¦æ•°
                # thetaä»[-1,1]è½¬æ¢å›[0,90]åº¦
                pred_theta_deg = (pred_angles[:, 0] * (np.pi/2)) * 180 / np.pi
                pred_phi_deg = (pred_angles[:, 1] * np.pi) * 180 / np.pi
                
                target_theta_deg = (theta_label[:, -1].cpu().numpy() * (np.pi/2)) * 180 / np.pi
                target_phi_deg = (phi_label[:, -1].cpu().numpy() * np.pi) * 180 / np.pi
                
                # è®¡ç®—è§’åº¦è¯¯å·®
                theta_error = np.abs(pred_theta_deg - target_theta_deg)
                phi_error = np.abs(pred_phi_deg - target_phi_deg)
                angle_errors.extend(theta_error + phi_error)
                
                # åˆ†ææ³¢æŸæˆå½¢æ€§èƒ½
                for i in range(len(pred_angles)):
                    try:
                        # é‡æ„å¤æ•°æƒé‡
                        weights_real = pred_beamforming[i, :256]
                        weights_imag = pred_beamforming[i, 256:]
                        weights = weights_real + 1j * weights_imag
                        
                        # æ£€æŸ¥æƒé‡çš„æœ‰æ•ˆæ€§
                        if np.any(np.isnan(weights)) or np.any(np.isinf(weights)):
                            weights = np.ones(256, dtype=complex) / np.sqrt(256)  # ä½¿ç”¨é»˜è®¤æƒé‡
                        else:
                            weights = weights / (np.linalg.norm(weights) + 1e-8)
                        
                        # è®¡ç®—æ³¢æŸå›¾
                        beam_pattern, _, _ = calculate_beam_pattern(
                            weights, [pred_theta_deg[i], pred_phi_deg[i]], antenna_positions
                        )
                        
                        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                        main_lobe_width, side_lobe_suppression = compute_beam_metrics(
                            beam_pattern, target_theta_deg[i], target_phi_deg[i]
                        )
                        
                        # å­é˜µåˆ—åˆ’åˆ†
                        subarray_assignment = np.argmax(pred_subarray[i])
                        
                        all_predictions.append({
                            'predicted_theta': pred_theta_deg[i],
                            'predicted_phi': pred_phi_deg[i],
                            'target_theta': target_theta_deg[i],
                            'target_phi': target_phi_deg[i],
                            'main_lobe_width': main_lobe_width,
                            'side_lobe_suppression': side_lobe_suppression,
                            'subarray_assignment': subarray_assignment,
                            'beamforming_weights': weights
                        })
                        
                    except Exception as e:
                        print(f"å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                        continue
                        
            except Exception as e:
                print(f"æµ‹è¯•æ‰¹æ¬¡é”™è¯¯: {e}")
                continue
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if len(angle_errors) > 0:
        mean_angle_error = np.mean(angle_errors)
        std_angle_error = np.std(angle_errors)
        
        print(f"\næµ‹è¯•ç»“æœ:")
        print(f"å¹³å‡è§’åº¦è¯¯å·®: {mean_angle_error:.2f}Â°")
        print(f"è§’åº¦è¯¯å·®æ ‡å‡†å·®: {std_angle_error:.2f}Â°")
        print(f"æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(all_predictions)}")
    else:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
        mean_angle_error = float('inf')
        std_angle_error = float('inf')
    
    return all_predictions

def main():
    """ä¸»å‡½æ•°"""
    # æŠ‘åˆ¶ä¸€äº›è­¦å‘Š
    warnings.filterwarnings('ignore', category=UserWarning)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®è·¯å¾„ï¼ˆéœ€è¦æ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
    channel_folder = "samples_data/channel_data_*"
    angle_folder = "samples_data/angle_data_*"
    
    # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶å¤¹
    channel_folders = glob.glob(channel_folder)
    angle_folders = glob.glob(angle_folder)
    
    if len(channel_folders) == 0 or len(angle_folders) == 0:
        print("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶å¤¹ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆä»£ç ")
        return
    
    print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶å¤¹: {len(channel_folders)} ä¸ªä¿¡é“æ–‡ä»¶å¤¹, {len(angle_folders)} ä¸ªè§’åº¦æ–‡ä»¶å¤¹")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BeamformingDataset(channel_folders[0], angle_folders[0])
    
    # æ•°æ®åˆ†å‰²
    indices = list(range(len(dataset)))
    train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)
    train_indices, val_indices = train_test_split(train_indices, test_size=0.2, random_state=42)
    
    print(f"æ•°æ®é›†åˆ’åˆ†: è®­ç»ƒ={len(train_indices)}, éªŒè¯={len(val_indices)}, æµ‹è¯•={len(test_indices)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡å¤§å°ï¼‰
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    test_dataset = torch.utils.data.Subset(dataset, test_indices)
    
    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=0)
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆç¨å¾®å‡å°æ¨¡å‹å¤æ‚åº¦ï¼‰
    model = MultiTaskBeamformingTransformer(
        input_dim=256*256*2,
        d_model=256,  # ä»512å‡å°åˆ°256
        nhead=8,
        num_layers=4,  # ä»6å‡å°åˆ°4
        num_subarrays=16,
        dropout=0.2  # å¢åŠ dropout
    )
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°ï¼‰
    print("\nå¼€å§‹è®­ç»ƒ...")
    train_losses, val_losses = train_model(
        model, train_loader, val_loader, 
        num_epochs=30,  # å‡å°‘è®­ç»ƒè½®æ•°
        lr=5e-6,       # é™ä½å­¦ä¹ ç‡
        device=device
    )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if os.path.exists('best_beamforming_model.pth'):
        model.load_state_dict(torch.load('best_beamforming_model.pth'))
        print("åŠ è½½æœ€ä½³æ¨¡å‹å®Œæˆ")
    
    # æµ‹è¯•æ¨¡å‹
    print("\nå¼€å§‹æµ‹è¯•...")
    predictions = test_model(model, test_loader, device=device)
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # æ”¯æŒä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['axes.unicode_minus'] = False  # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
    
    plt.figure(figsize=(15, 5))
    
    # è®­ç»ƒæŸå¤±æ›²çº¿
    plt.subplot(1, 3, 1)
    if len(train_losses) > 0 and len(val_losses) > 0:
        plt.plot(train_losses, label='Training Loss', alpha=0.8)
        plt.plot(val_losses, label='Validation Loss', alpha=0.8)
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.title('Training Process')
        plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°å°ºåº¦
    
    # è§’åº¦é¢„æµ‹ç»“æœ
    plt.subplot(1, 3, 2)
    if len(predictions) > 0:
        pred_theta = [p['predicted_theta'] for p in predictions if 'predicted_theta' in p]
        target_theta = [p['target_theta'] for p in predictions if 'target_theta' in p]
        
        if len(pred_theta) > 0 and len(target_theta) > 0:
            plt.scatter(target_theta, pred_theta, alpha=0.6, s=30)
            min_angle, max_angle = min(min(target_theta), min(pred_theta)), max(max(target_theta), max(pred_theta))
            plt.plot([min_angle, max_angle], [min_angle, max_angle], 'r--', label='Perfect Prediction')
            plt.xlabel('True Angle Î¸ (degrees)')
            plt.ylabel('Predicted Angle Î¸ (degrees)')
            plt.legend()
            plt.title('Angle Prediction Results')
    
    # æŸå¤±åˆ†è§£
    plt.subplot(1, 3, 3)
    if len(train_losses) > 1:
        epochs = range(1, len(train_losses) + 1)
        plt.plot(epochs, train_losses, 'b-', label='Training Loss', alpha=0.7)
        plt.plot(epochs, val_losses, 'r-', label='Validation Loss', alpha=0.7)
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Loss Comparison')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_results.png', dpi=300, bbox_inches='tight')
    print(f"\nè®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º 'training_results.png'")
    
    # æ˜¾ç¤ºè®­ç»ƒæ€»ç»“
    print(f"\nğŸ“Š è®­ç»ƒæ€»ç»“:")
    print(f"â€¢ æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.4f}" if train_losses else "â€¢ æ— è®­ç»ƒæŸå¤±è®°å½•")
    print(f"â€¢ æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.4f}" if val_losses else "â€¢ æ— éªŒè¯æŸå¤±è®°å½•")
    print(f"â€¢ æ€»è®­ç»ƒè½®æ•°: {len(train_losses)}")
    print(f"â€¢ æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(predictions)}")
    
    try:
        plt.show()
    except:
        print("æ— æ³•æ˜¾ç¤ºå›¾è¡¨ï¼Œä½†å·²ä¿å­˜åˆ°æ–‡ä»¶")

if __name__ == "__main__":
    main() 