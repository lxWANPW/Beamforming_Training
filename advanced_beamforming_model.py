import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import scipy.io as sio
import h5py
import os
import glob
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from torch.nn import TransformerEncoder, TransformerEncoderLayer
import math
from tqdm import tqdm
import warnings
from torch.cuda.amp import GradScaler
import torch.multiprocessing as mp
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
import subprocess
import os

class BeamformingDataset(Dataset):
    """ä¿®å¤ç‰ˆå¤©çº¿é˜µåˆ—ä¿¡é“æ•°æ®é›†"""
    def __init__(self, channel_folder, angle_folder, transform=None, use_augmentation=True):
        self.channel_folder = channel_folder
        self.angle_folder = angle_folder
        self.transform = transform
        self.use_augmentation = use_augmentation
        
        # è·å–ä¿¡é“æ•°æ®æ–‡ä»¶åˆ—è¡¨å¹¶æ’åº
        self.channel_files = sorted(glob.glob(os.path.join(channel_folder, '*.mat')))
        print(f"æ‰¾åˆ°ä¿¡é“æ•°æ®æ–‡ä»¶: {len(self.channel_files)} ä¸ª")
        
        # åŠ è½½è§’åº¦æ•°æ®ï¼ˆæ‰€æœ‰æ ·æœ¬çš„è§’åº¦ä¿¡æ¯åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼‰
        angle_files = glob.glob(os.path.join(angle_folder, '*.mat'))
        if len(angle_files) > 0:
            try:
                # å°è¯•ä½¿ç”¨ h5py è¯»å–
                with h5py.File(angle_files[0], 'r') as f:
                    all_theta = np.array(f['all_theta'])  # (50, 1000) or (1000, 50)
                    all_phi = np.array(f['all_phi'])      # (50, 1000) or (1000, 50)
                    
                    # æ£€æŸ¥ç»´åº¦å¹¶è°ƒæ•´
                    if all_theta.shape[0] == 50 and all_theta.shape[1] == 1000:
                        self.theta_array = all_theta.T  # (1000, 50)
                        self.phi_array = all_phi.T      # (1000, 50)
                    else:
                        self.theta_array = all_theta    # å‡è®¾å·²ç»æ˜¯(1000, 50)
                        self.phi_array = all_phi
                    
                    self.num_samples = self.theta_array.shape[0]
                    self.num_time_samples = self.theta_array.shape[1]
                    
                    print(f"è§’åº¦æ•°æ®å½¢çŠ¶: theta={self.theta_array.shape}, phi={self.phi_array.shape}")
                    
            except Exception as e:
                print(f"h5py è¯»å–å¤±è´¥: {e}")
                # ä½¿ç”¨ scipy.io è¯»å–
                try:
                    angle_data = sio.loadmat(angle_files[0])
                    # æ£€æŸ¥å¯èƒ½çš„é”®å
                    possible_keys = ['all_theta', 'theta_array', 'theta']
                    theta_key = None
                    phi_key = None
                    
                    for key in angle_data.keys():
                        if 'theta' in key.lower():
                            theta_key = key
                        if 'phi' in key.lower():
                            phi_key = key
                    
                    if theta_key and phi_key:
                        all_theta = angle_data[theta_key]
                        all_phi = angle_data[phi_key]
                        
                        if all_theta.shape[0] == 50 and all_theta.shape[1] == 1000:
                            self.theta_array = all_theta.T
                            self.phi_array = all_phi.T
                        else:
                            self.theta_array = all_theta
                            self.phi_array = all_phi
                            
                        self.num_samples = self.theta_array.shape[0]
                        self.num_time_samples = self.theta_array.shape[1]
                    else:
                        raise ValueError("æœªæ‰¾åˆ°thetaå’Œphiæ•°æ®")
                        
                except Exception as e2:
                    print(f"scipy.io è¯»å–ä¹Ÿå¤±è´¥: {e2}")
                    print(f"è§’åº¦æ–‡ä»¶å†…å®¹: {list(angle_data.keys()) if 'angle_data' in locals() else 'Unknown'}")
                    raise e2
        
        # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼Œä½¿ç”¨è¾ƒå°çš„æ•°é‡
        self.actual_num_samples = min(len(self.channel_files), self.num_samples)
        print(f"å®é™…ä½¿ç”¨çš„æ ·æœ¬æ•°é‡: {self.actual_num_samples}")
        
    def __len__(self):
        return self.actual_num_samples
    
    def _add_data_augmentation(self, H_real, H_imag, theta_rad, phi_rad):
        """æ•°æ®å¢å¼ºç­–ç•¥"""
        if not self.use_augmentation:
            return H_real, H_imag, theta_rad, phi_rad
            
        # 1. å™ªå£°å¢å¼º
        noise_std = 0.01
        H_real = H_real + np.random.normal(0, noise_std, H_real.shape)
        H_imag = H_imag + np.random.normal(0, noise_std, H_imag.shape)
        
        # 2. æ—‹è½¬å¢å¼º (å°è§’åº¦æ—‹è½¬)
        angle_noise_std = 0.02  # çº¦1.1åº¦çš„æ ‡å‡†å·®
        theta_rad = theta_rad + np.random.normal(0, angle_noise_std, theta_rad.shape)
        phi_rad = phi_rad + np.random.normal(0, angle_noise_std, phi_rad.shape)
        
        # 3. å¹…åº¦ç¼©æ”¾
        scale_factor = np.random.uniform(0.95, 1.05)
        H_real = H_real * scale_factor
        H_imag = H_imag * scale_factor
        
        return H_real, H_imag, theta_rad, phi_rad
    
    def __getitem__(self, idx):
        if idx >= self.actual_num_samples:
            raise IndexError(f"ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ {self.actual_num_samples}")
            
        # åŠ è½½ä¿¡é“æ•°æ®
        try:
            # å°è¯•ä½¿ç”¨ h5py è¯»å–
            with h5py.File(self.channel_files[idx], 'r') as f:
                H_real = np.array(f['H_real'])  # (50, 256, 256)
                H_imag = np.array(f['H_imag'])  # (50, 256, 256)
                
                # è½¬ç½®ä»¥åŒ¹é…é¢„æœŸæ ¼å¼ [256, 256, 50]
                H_real = H_real.transpose(1, 2, 0)  # (256, 256, 50)
                H_imag = H_imag.transpose(1, 2, 0)  # (256, 256, 50)
                
        except Exception as e:
            # ä½¿ç”¨ scipy.io è¯»å–
            try:
                channel_data = sio.loadmat(self.channel_files[idx])
                H_real = channel_data['H_real']  # [256, 256, 50]
                H_imag = channel_data['H_imag']
            except Exception as e2:
                print(f"æ— æ³•è¯»å–ä¿¡é“æ•°æ®æ–‡ä»¶ {self.channel_files[idx]}: {e2}")
                raise e2
        
        # è·å–è§’åº¦æ•°æ®
        theta_rad = self.theta_array[idx] * np.pi / 180  # è½¬æ¢ä¸ºå¼§åº¦
        phi_rad = self.phi_array[idx] * np.pi / 180
        
        # æ•°æ®å¢å¼º
        H_real, H_imag, theta_rad, phi_rad = self._add_data_augmentation(
            H_real, H_imag, theta_rad, phi_rad
        )
        
        # ç»„åˆå®éƒ¨å’Œè™šéƒ¨
        H_complex = H_real + 1j * H_imag
        
        # æ”¹è¿›çš„æ•°æ®å½’ä¸€åŒ–ï¼ˆé¿å…æå€¼ï¼‰
        H_real_std = np.std(H_real)
        H_imag_std = np.std(H_imag)
        
        if H_real_std > 1e-8:
            H_real_norm = (H_real - np.mean(H_real)) / H_real_std
        else:
            H_real_norm = H_real
            
        if H_imag_std > 1e-8:
            H_imag_norm = (H_imag - np.mean(H_imag)) / H_imag_std
        else:
            H_imag_norm = H_imag
        
        # è£å‰ªæå€¼ä»¥é¿å…æ¢¯åº¦çˆ†ç‚¸
        H_real_norm = np.clip(H_real_norm, -8, 8)
        H_imag_norm = np.clip(H_imag_norm, -8, 8)
        
        # è½¬æ¢ä¸ºPyTorch tensor
        H_input = np.stack([H_real_norm, H_imag_norm], axis=0)  # [2, 256, 256, 50]
        H_input = torch.FloatTensor(H_input)
        
        # æ”¹è¿›çš„è§’åº¦æ ‡ç­¾å½’ä¸€åŒ–
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„å½’ä¸€åŒ–æ–¹å¼
        theta_norm = theta_rad / (np.pi / 2)  # å½’ä¸€åŒ–åˆ°[-2, 2]èŒƒå›´ï¼Œç„¶åè£å‰ª
        phi_norm = phi_rad / np.pi  # å½’ä¸€åŒ–åˆ°[-1, 1]
        
        theta_norm = np.clip(theta_norm, -1, 1)
        phi_norm = np.clip(phi_norm, -1, 1)
        
        theta_label = torch.FloatTensor(theta_norm)  # [50]
        phi_label = torch.FloatTensor(phi_norm)      # [50]
        
        return H_input, theta_label, phi_label, H_complex

class AdvancedPositionalEncoding(nn.Module):
    """æ”¹è¿›çš„ä½ç½®ç¼–ç ï¼Œæ”¯æŒ2Dç©ºé—´ä¿¡æ¯"""
    def __init__(self, d_model, max_len=5000, spatial_dims=None):
        super(AdvancedPositionalEncoding, self).__init__()
        
        # æ—¶é—´ä½ç½®ç¼–ç 
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
        
        # å­¦ä¹ å¼ä½ç½®ç¼–ç 
        self.learned_pe = nn.Parameter(torch.randn(max_len, d_model) * 0.02)
        
    def forward(self, x):
        # ç»„åˆå›ºå®šå’Œå­¦ä¹ å¼ä½ç½®ç¼–ç 
        return x + self.pe[:x.size(0), :] + self.learned_pe[:x.size(0), :]

class SpatialAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…³æ³¨é‡è¦çš„ç©ºé—´ç‰¹å¾"""
    def __init__(self, d_model):
        super(SpatialAttention, self).__init__()
        self.spatial_conv = nn.Sequential(
            nn.Conv2d(d_model, d_model // 4, kernel_size=3, padding=1),
            nn.BatchNorm2d(d_model // 4),
            nn.ReLU(),
            nn.Conv2d(d_model // 4, 1, kernel_size=1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        # x: [batch, time, d_model]
        # éœ€è¦é‡å¡‘ä¸ºç©ºé—´ç»´åº¦è¿›è¡Œç©ºé—´æ³¨æ„åŠ›è®¡ç®—
        B, T, D = x.shape
        sqrt_d = int(math.sqrt(D))
        if sqrt_d * sqrt_d == D:
            # å¦‚æœå¯ä»¥å®Œç¾å¼€æ–¹ï¼Œé‡å¡‘ä¸º2D
            x_2d = x.view(B, T, sqrt_d, sqrt_d)
            x_2d = x_2d.permute(0, 1, 2, 3).contiguous()
            
            # åº”ç”¨ç©ºé—´æ³¨æ„åŠ›åˆ°æ¯ä¸ªæ—¶é—´æ­¥
            attention_maps = []
            for t in range(T):
                att_map = self.spatial_conv(x_2d[:, t:t+1])  # [B, 1, sqrt_d, sqrt_d]
                attention_maps.append(att_map)
            
            attention = torch.cat(attention_maps, dim=1)  # [B, T, sqrt_d, sqrt_d]
            attention = attention.view(B, T, D)
            
            return x * attention
        else:
            # å¦‚æœä¸èƒ½å®Œç¾å¼€æ–¹ï¼Œç›´æ¥è¿”å›
            return x

class MultiScaleFeatureExtractor(nn.Module):
    """å¤šå°ºåº¦ç‰¹å¾æå–å™¨ï¼Œæå–ä¸åŒå±‚æ¬¡çš„ç‰¹å¾"""
    def __init__(self, input_dim, d_model, dropout=0.1):
        super(MultiScaleFeatureExtractor, self).__init__()
        
        # åˆ†é˜¶æ®µé™ç»´ï¼Œå‡å°‘å‚æ•°é‡
        intermediate_dims = [input_dim, input_dim//4, input_dim//16, d_model*2, d_model]
        
        self.feature_layers = nn.ModuleList()
        for i in range(len(intermediate_dims)-1):
            self.feature_layers.append(
                nn.Sequential(
                    nn.Conv1d(intermediate_dims[i], intermediate_dims[i+1], kernel_size=1),
                    nn.BatchNorm1d(intermediate_dims[i+1]),
                    nn.GELU(),
                    nn.Dropout(dropout)
                )
            )
        
        # å¤šå°ºåº¦åˆ†æ”¯
        self.multi_scale_branches = nn.ModuleList([
            # å±€éƒ¨ç‰¹å¾ (å°æ„Ÿå—é‡)
            nn.Sequential(
                nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model//8),
                nn.BatchNorm1d(d_model),
                nn.GELU(),
            ),
            # ä¸­ç­‰æ„Ÿå—é‡
            nn.Sequential(
                nn.Conv1d(d_model, d_model, kernel_size=5, padding=2, groups=d_model//8),
                nn.BatchNorm1d(d_model),
                nn.GELU(),
            ),
            # å…¨å±€ç‰¹å¾ (å¤§æ„Ÿå—é‡)
            nn.Sequential(
                nn.Conv1d(d_model, d_model, kernel_size=7, padding=3, groups=d_model//8),
                nn.BatchNorm1d(d_model),
                nn.GELU(),
            )
        ])
        
        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Conv1d(d_model * 4, d_model, kernel_size=1),  # 3ä¸ªåˆ†æ”¯ + åŸå§‹ç‰¹å¾
            nn.BatchNorm1d(d_model),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        
    def forward(self, x):
        # é€æ­¥é™ç»´
        for layer in self.feature_layers:
            x = layer(x)
        
        # å¤šå°ºåº¦ç‰¹å¾æå–
        original_features = x
        multi_scale_features = []
        for branch in self.multi_scale_branches:
            multi_scale_features.append(branch(x))
        
        # èåˆæ‰€æœ‰ç‰¹å¾
        all_features = torch.cat([original_features] + multi_scale_features, dim=1)
        fused_features = self.fusion(all_features)
        
        return fused_features

class AdvancedTransformerBeamformingNet(nn.Module):
    """é«˜çº§Transformeræ³¢æŸæˆå½¢ç½‘ç»œï¼Œæ˜¾è‘—æå‡è§’åº¦é¢„æµ‹ç²¾åº¦ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    def __init__(self, input_dim=256*256*2, d_model=768, nhead=12, num_layers=8, dropout=0.1):
        super(AdvancedTransformerBeamformingNet, self).__init__()
        
        self.d_model = d_model
        
        # ä¼˜åŒ–çš„å¤šå°ºåº¦ç‰¹å¾æå–å™¨ï¼ˆå‡å°‘å‚æ•°ï¼‰
        self.feature_extractor = MultiScaleFeatureExtractor(
            input_dim=input_dim,
            d_model=d_model,
            dropout=dropout
        )
        
        # æ”¹è¿›çš„ä½ç½®ç¼–ç 
        self.pos_encoder = AdvancedPositionalEncoding(d_model, max_len=100)
        
        # ç©ºé—´æ³¨æ„åŠ›ï¼ˆç®€åŒ–ç‰ˆï¼‰
        self.spatial_attention = SpatialAttention(d_model)
        
        # ä¼˜åŒ–çš„Transformerç¼–ç å™¨å±‚ï¼ˆå‡å°‘å±‚æ•°å’ŒFFNå¤§å°ï¼‰
        encoder_layers = TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 2,  # å‡å°‘FFNå¤§å°
            dropout=dropout,
            activation='gelu',
            batch_first=True,
            norm_first=True
        )
        self.transformer_encoder = TransformerEncoder(
            encoder_layers, 
            num_layers=num_layers,
            norm=nn.LayerNorm(d_model)
        )
        
        # å•çº§æ³¨æ„åŠ›èšåˆï¼ˆå‡å°‘å†…å­˜ä½¿ç”¨ï¼‰
        self.attention_pooling = nn.MultiheadAttention(
            embed_dim=d_model,
            num_heads=nhead,
            dropout=dropout,
            batch_first=True
        )
        
        # ä¼˜åŒ–çš„è§’åº¦é¢„æµ‹å¤´
        self.shared_predictor = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model // 4),
            nn.LayerNorm(d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout * 0.5),
        )
        
        # Thetaé¢„æµ‹åˆ†æ”¯
        self.theta_predictor = nn.Sequential(
            nn.Linear(d_model // 4, 128),
            nn.GELU(),
            nn.Dropout(dropout * 0.3),
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Linear(64, 1)
        )
        
        # Phié¢„æµ‹åˆ†æ”¯
        self.phi_predictor = nn.Sequential(
            nn.Linear(d_model // 4, 128),
            nn.GELU(),
            nn.Dropout(dropout * 0.3),
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Linear(64, 1)
        )
        
        # å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡
        self.query_vector = nn.Parameter(torch.randn(1, 1, d_model) * 0.02)
        
        # æƒé‡åˆå§‹åŒ–
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_normal_(module.weight, gain=0.8)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm1d, nn.BatchNorm2d)):
            nn.init.constant_(module.bias, 0)
            nn.init.constant_(module.weight, 1.0)
        elif isinstance(module, (nn.Conv1d, nn.Conv2d)):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                    
    def forward(self, x):
        batch_size, channels, height, width, time_steps = x.shape
        
        # é‡å¡‘è¾“å…¥ [batch, time_steps, features]
        x = x.permute(0, 4, 1, 2, 3)  # [batch, time_steps, channels, height, width]
        x = x.reshape(batch_size, time_steps, -1)  # [batch, time_steps, features]
        
        # å¤šå°ºåº¦ç‰¹å¾æå–
        x = x.permute(0, 2, 1)  # [batch, features, time_steps]
        x = self.feature_extractor(x)  # [batch, d_model, time_steps]
        x = x.permute(0, 2, 1)  # [batch, time_steps, d_model]
        
        # ç©ºé—´æ³¨æ„åŠ›
        x = self.spatial_attention(x)
        
        # ä½ç½®ç¼–ç å’Œç¼©æ”¾
        x = x * math.sqrt(self.d_model)
        x = x.transpose(0, 1)  # [time_steps, batch, d_model]
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)  # [batch, time_steps, d_model]
        
        # Transformerç¼–ç 
        encoded = self.transformer_encoder(x)  # [batch, time_steps, d_model]
        
        # æ³¨æ„åŠ›èšåˆ
        query = self.query_vector.expand(batch_size, -1, -1)
        aggregated, _ = self.attention_pooling(query, encoded, encoded)
        
        final_features = aggregated.squeeze(1)  # [batch, d_model]
        
        # å…±äº«ç‰¹å¾æå–
        shared_features = self.shared_predictor(final_features)
        
        # åˆ†ç¦»é¢„æµ‹
        theta_pred = self.theta_predictor(shared_features)  # [batch, 1]
        phi_pred = self.phi_predictor(shared_features)      # [batch, 1]
        
        # ç»„åˆè¾“å‡º
        angles = torch.cat([theta_pred, phi_pred], dim=1)  # [batch, 2]
        
        return angles

class AdvancedLossFunction(nn.Module):
    """é«˜çº§æŸå¤±å‡½æ•°ï¼Œç»“åˆå¤šç§æŸå¤±ç­–ç•¥"""
    def __init__(self, alpha=1.0, beta=1.0, gamma=0.5):
        super(AdvancedLossFunction, self).__init__()
        self.alpha = alpha  # Focal lossæƒé‡
        self.beta = beta    # Huber lossæƒé‡
        self.gamma = gamma  # Contrastive learningæƒé‡
        
    def focal_huber_loss(self, pred, target, delta=0.5):
        """Focal HuberæŸå¤±"""
        error = torch.abs(pred - target)
        focal_weight = torch.pow(error + 1e-8, 0.3)  # æ›´æ¸©å’Œçš„æƒé‡
        huber_loss = F.huber_loss(pred, target, delta=delta, reduction='none')
        return (focal_weight * huber_loss).mean()
    
    def angle_consistency_loss(self, pred_theta, pred_phi, target_theta, target_phi):
        """è§’åº¦ä¸€è‡´æ€§æŸå¤±ï¼Œè€ƒè™‘è§’åº¦çš„å‘¨æœŸæ€§"""
        # ThetaæŸå¤±
        theta_diff = pred_theta - target_theta
        theta_loss = torch.min(torch.abs(theta_diff), 
                              torch.abs(theta_diff + 2), 
                              torch.abs(theta_diff - 2))
        
        # PhiæŸå¤±
        phi_diff = pred_phi - target_phi
        phi_loss = torch.min(torch.abs(phi_diff), 
                            torch.abs(phi_diff + 2), 
                            torch.abs(phi_diff - 2))
        
        return theta_loss.mean() + phi_loss.mean()
    
    def smoothness_loss(self, predictions):
        """å¹³æ»‘æ€§æŸå¤±ï¼Œå‡å°‘é¢„æµ‹çš„çªå˜"""
        # å¯¹äºbatchå†…çš„é¢„æµ‹å€¼ï¼Œè®¡ç®—ç›¸é‚»æ ·æœ¬çš„å·®å¼‚
        if predictions.size(0) > 1:
            diff = torch.diff(predictions, dim=0)
            return torch.mean(torch.abs(diff))
        return torch.tensor(0.0, device=predictions.device)
    
    def forward(self, predictions, targets):
        pred_angles = predictions  # [batch, 2]
        target_theta, target_phi = targets
        
        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç›®æ ‡
        target_theta_last = target_theta[:, -1]  # [batch]
        target_phi_last = target_phi[:, -1]      # [batch]
        
        # ä¸»è¦æŸå¤±ï¼šFocal Huber
        theta_loss = self.focal_huber_loss(pred_angles[:, 0], target_theta_last)
        phi_loss = self.focal_huber_loss(pred_angles[:, 1], target_phi_last)
        main_loss = self.alpha * (theta_loss + phi_loss)
        
        # è§’åº¦ä¸€è‡´æ€§æŸå¤±
        consistency_loss = self.beta * self.angle_consistency_loss(
            pred_angles[:, 0], pred_angles[:, 1], 
            target_theta_last, target_phi_last
        )
        
        # å¹³æ»‘æ€§æŸå¤±
        smooth_loss = self.gamma * self.smoothness_loss(pred_angles)
        
        total_loss = main_loss + consistency_loss + smooth_loss
        
        # é˜²æ­¢æŸå¤±çˆ†ç‚¸
        total_loss = torch.clamp(total_loss, 0, 100)
        
        return total_loss, theta_loss, phi_loss

def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if 'WORLD_SIZE' in os.environ:
        # ä»ç¯å¢ƒå˜é‡è·å–åˆ†å¸ƒå¼ä¿¡æ¯
        world_size = int(os.environ['WORLD_SIZE'])
        rank = int(os.environ['RANK'])
        local_rank = int(os.environ['LOCAL_RANK'])
        
        print(f"åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒ: world_size={world_size}, rank={rank}, local_rank={local_rank}")
        
        # è®¾ç½®CUDAè®¾å¤‡
        torch.cuda.set_device(local_rank)
        
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        if not dist.is_initialized():
            dist.init_process_group(
                backend='nccl',
                init_method='env://',
                world_size=world_size,
                rank=rank
            )
            print(f"Rank {rank}: åˆ†å¸ƒå¼è¿›ç¨‹ç»„åˆå§‹åŒ–å®Œæˆ")
        
        return world_size, rank, local_rank
    else:
        # éåˆ†å¸ƒå¼ç¯å¢ƒ
        return 1, 0, 0

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def train_advanced_model(model, train_loader, val_loader, num_epochs=200, lr=2e-4, device='cuda', use_distributed=False):
    """é«˜çº§æ¨¡å‹è®­ç»ƒå‡½æ•° - å¤šGPUæ”¯æŒç‰ˆæœ¬"""
    # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
    world_size, rank, local_rank = 1, 0, 0
    if use_distributed:
        world_size, rank, local_rank = setup_distributed()
        if dist.is_initialized():
            device = f'cuda:{local_rank}'
        else:
            print("åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°å•GPUè®­ç»ƒ")
            use_distributed = False
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        
    model.to(device)
    
    # åŒ…è£…ä¸ºåˆ†å¸ƒå¼æ¨¡å‹
    if use_distributed and dist.is_initialized() and world_size > 1:
        model = DDP(model, device_ids=[local_rank], output_device=local_rank, find_unused_parameters=True)
        print(f"Rank {rank}: æ¨¡å‹å·²åŒ…è£…ä¸ºDDP")
    
    # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()
    
    # ä¼˜åŒ–å™¨è®¾ç½® - é’ˆå¯¹åˆ†å¸ƒå¼è®­ç»ƒè°ƒæ•´å­¦ä¹ ç‡
    effective_lr = lr * world_size if use_distributed and dist.is_initialized() and world_size > 1 else lr
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=effective_lr, 
        weight_decay=1e-4,
        eps=1e-8,
        betas=(0.9, 0.999)
    )
    
    # å­¦ä¹ ç‡è°ƒåº¦
    warmup_epochs = 20
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=effective_lr,
        epochs=num_epochs,
        steps_per_epoch=len(train_loader),
        pct_start=warmup_epochs/num_epochs,
        div_factor=20,
        final_div_factor=1000,
        anneal_strategy='cos'
    )
    
    # é«˜çº§æŸå¤±å‡½æ•°
    criterion = AdvancedLossFunction(alpha=1.0, beta=0.5, gamma=0.2)
    
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 50
    min_improvement = 5e-6
    
    # æ¢¯åº¦ç´¯ç§¯è®¾ç½®
    accumulation_steps = 2  # æ¯2ä¸ªbatchç´¯ç§¯ä¸€æ¬¡æ¢¯åº¦
    
    # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°è®­ç»ƒä¿¡æ¯
    is_main_process = rank == 0
    if is_main_process:
        print(f"å¼€å§‹é«˜çº§æ¨¡å‹è®­ç»ƒï¼Œå­¦ä¹ ç‡: {effective_lr}, æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
        if use_distributed and dist.is_initialized() and world_size > 1:
            print(f"ä½¿ç”¨ {world_size} ä¸ªGPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ")
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_epoch = 0
        train_theta_loss = 0
        train_phi_loss = 0
        num_batches = 0
        
        train_progress = tqdm(train_loader, desc=f"è®­ç»ƒ Epoch {epoch+1}/{num_epochs}", leave=False, disable=not is_main_process)
        
        optimizer.zero_grad()  # åœ¨epochå¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
        
        for batch_idx, (H_input, theta_label, phi_label, H_complex) in enumerate(train_progress):
            try:
                H_input = H_input.to(device, non_blocking=True)
                theta_label = theta_label.to(device, non_blocking=True)
                phi_label = phi_label.to(device, non_blocking=True)
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§
                if torch.isnan(H_input).any() or torch.isinf(H_input).any():
                    continue
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                with torch.amp.autocast('cuda'):
                    predictions = model(H_input)
                    loss, theta_loss, phi_loss = criterion(predictions, (theta_label, phi_label))
                    loss = loss / accumulation_steps  # å½’ä¸€åŒ–æŸå¤±
                
                # æ£€æŸ¥æŸå¤±çš„æœ‰æ•ˆæ€§
                if torch.isnan(loss) or torch.isinf(loss):
                    continue
                
                # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                
                # æ¢¯åº¦ç´¯ç§¯
                if (batch_idx + 1) % accumulation_steps == 0:
                    scaler.unscale_(optimizer)
                    # æ¢¯åº¦è£å‰ª
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    scaler.step(optimizer)
                    scaler.update()
                    scheduler.step()
                    optimizer.zero_grad()
                
                train_loss_epoch += loss.item() * accumulation_steps
                train_theta_loss += theta_loss.item()
                train_phi_loss += phi_loss.item()
                num_batches += 1
                
                # æ›´æ–°è¿›åº¦æ¡
                current_lr = optimizer.param_groups[0]['lr']
                train_progress.set_postfix({
                    'Loss': f'{loss.item() * accumulation_steps:.5f}',
                    'Î¸': f'{theta_loss.item():.5f}',
                    'Ï†': f'{phi_loss.item():.5f}',
                    'LR': f'{current_lr:.2e}'
                })
                
                # å®šæœŸæ¸…ç†ç¼“å­˜
                if batch_idx % 10 == 0:
                    torch.cuda.empty_cache()
                
            except Exception as e:
                if is_main_process:
                    print(f"è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                # æ¸…ç†ç¼“å­˜å¹¶ç»§ç»­
                torch.cuda.empty_cache()
                continue
        
        # åŒæ­¥æ‰€æœ‰è¿›ç¨‹çš„æ¢¯åº¦ç»Ÿè®¡
        if use_distributed and dist.is_initialized() and world_size > 1:
            # æ”¶é›†æ‰€æœ‰è¿›ç¨‹çš„æŸå¤±
            train_loss_tensor = torch.tensor(train_loss_epoch, device=device)
            train_theta_tensor = torch.tensor(train_theta_loss, device=device)
            train_phi_tensor = torch.tensor(train_phi_loss, device=device)
            batch_count_tensor = torch.tensor(num_batches, device=device)
            
            dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)
            dist.all_reduce(train_theta_tensor, op=dist.ReduceOp.SUM)
            dist.all_reduce(train_phi_tensor, op=dist.ReduceOp.SUM)
            dist.all_reduce(batch_count_tensor, op=dist.ReduceOp.SUM)
            
            train_loss_epoch = train_loss_tensor.item()
            train_theta_loss = train_theta_tensor.item()
            train_phi_loss = train_phi_tensor.item()
            num_batches = batch_count_tensor.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_epoch = 0
        val_theta_loss = 0
        val_phi_loss = 0
        val_batches = 0
        
        with torch.no_grad():
            val_progress = tqdm(val_loader, desc="éªŒè¯", leave=False, disable=not is_main_process)
            for H_input, theta_label, phi_label, H_complex in val_progress:
                try:
                    H_input = H_input.to(device, non_blocking=True)
                    theta_label = theta_label.to(device, non_blocking=True)
                    phi_label = phi_label.to(device, non_blocking=True)
                    
                    with torch.amp.autocast('cuda'):
                        predictions = model(H_input)
                        loss, theta_loss, phi_loss = criterion(predictions, (theta_label, phi_label))
                    
                    if not (torch.isnan(loss) or torch.isinf(loss)):
                        val_loss_epoch += loss.item()
                        val_theta_loss += theta_loss.item()
                        val_phi_loss += phi_loss.item()
                        val_batches += 1
                        
                except Exception as e:
                    continue
            
            # åŒæ­¥éªŒè¯æŸå¤±
            if use_distributed and dist.is_initialized() and world_size > 1:
                val_loss_tensor = torch.tensor(val_loss_epoch, device=device)
                val_theta_tensor = torch.tensor(val_theta_loss, device=device)
                val_phi_tensor = torch.tensor(val_phi_loss, device=device)
                val_batch_tensor = torch.tensor(val_batches, device=device)
                
                dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)
                dist.all_reduce(val_theta_tensor, op=dist.ReduceOp.SUM)
                dist.all_reduce(val_phi_tensor, op=dist.ReduceOp.SUM)
                dist.all_reduce(val_batch_tensor, op=dist.ReduceOp.SUM)
                
                val_loss_epoch = val_loss_tensor.item()
                val_theta_loss = val_theta_tensor.item()
                val_phi_loss = val_phi_tensor.item()
                val_batches = val_batch_tensor.item()
            
            # æ¸…ç†éªŒè¯é˜¶æ®µç¼“å­˜
            torch.cuda.empty_cache()
        
        # è®¡ç®—å¹³å‡æŸå¤±
        if num_batches > 0:
            train_loss_avg = train_loss_epoch / num_batches
            train_theta_avg = train_theta_loss / num_batches
            train_phi_avg = train_phi_loss / num_batches
        else:
            train_loss_avg = float('inf')
            train_theta_avg = float('inf')
            train_phi_avg = float('inf')
            
        if val_batches > 0:
            val_loss_avg = val_loss_epoch / val_batches
            val_theta_avg = val_theta_loss / val_batches
            val_phi_avg = val_phi_loss / val_batches
        else:
            val_loss_avg = float('inf')
            val_theta_avg = float('inf')
            val_phi_avg = float('inf')
        
        train_losses.append(train_loss_avg)
        val_losses.append(val_loss_avg)
        
        # åŠ¨æ€æ—©åœç­–ç•¥
        current_early_stop_patience = early_stop_patience
        if val_loss_avg < 0.0005:  # æ›´ä¸¥æ ¼çš„é˜ˆå€¼
            current_early_stop_patience = 80
        
        # æ‰“å°epochç»“æœ (åªåœ¨ä¸»è¿›ç¨‹)
        current_lr = optimizer.param_groups[0]['lr']
        train_val_gap = val_loss_avg - train_loss_avg
        if is_main_process:
            print(f"Epoch {epoch+1:3d}: Train={train_loss_avg:.7f} (Î¸:{train_theta_avg:.7f}, Ï†:{train_phi_avg:.7f}), "
                  f"Val={val_loss_avg:.7f} (Î¸:{val_theta_avg:.7f}, Ï†:{val_phi_avg:.7f}), "
                  f"Gap={train_val_gap:.7f}, LR={current_lr:.2e}, Patience={patience_counter}/{current_early_stop_patience}")
        
        # æ—©åœå’Œæ¨¡å‹ä¿å­˜ (åªåœ¨ä¸»è¿›ç¨‹)
        improvement = best_val_loss - val_loss_avg
        if improvement > min_improvement:
            best_val_loss = val_loss_avg
            patience_counter = 0
            if is_main_process:
                # ä¿å­˜æ¨¡å‹æ—¶éœ€è¦å¤„ç†DDPåŒ…è£…
                model_to_save = model.module if hasattr(model, 'module') else model
                torch.save(model_to_save.state_dict(), 'best_advanced_beamforming_model.pth')
                print(f"âœ“ ä¿å­˜æœ€ä½³é«˜çº§æ¨¡å‹ (Val Loss: {val_loss_avg:.7f}, æ”¹è¿›: {improvement:.7f})")
        else:
            patience_counter += 1
            
        if patience_counter >= current_early_stop_patience:
            if is_main_process:
                print(f"æ—©åœè§¦å‘ï¼åœ¨epoch {epoch+1}åœæ­¢è®­ç»ƒ (patience: {patience_counter}/{current_early_stop_patience})")
            break
    
    # æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ
    if use_distributed and dist.is_initialized():
        cleanup_distributed()
    
    return train_losses, val_losses

def test_advanced_model(model, test_loader, device='cuda'):
    """æµ‹è¯•é«˜çº§æ¨¡å‹æ€§èƒ½"""
    model.to(device)
    model.eval()
    
    all_predictions = []
    angle_errors = []
    
    with torch.no_grad():
        test_progress = tqdm(test_loader, desc="é«˜çº§æ¨¡å‹æµ‹è¯•")
        
        for H_input, theta_label, phi_label, H_complex in test_progress:
            try:
                H_input = H_input.to(device)
                theta_label = theta_label.to(device)
                phi_label = phi_label.to(device)
                
                # é¢„æµ‹
                with torch.amp.autocast('cuda'):
                    predictions = model(H_input)
                
                # è½¬æ¢ä¸ºåº¦æ•°ï¼ˆåå½’ä¸€åŒ–ï¼‰
                pred_angles = predictions.cpu().numpy()
                pred_theta_norm = pred_angles[:, 0]  # [-1, 1]
                pred_phi_norm = pred_angles[:, 1]    # [-1, 1]
                
                # åå½’ä¸€åŒ–åˆ°åº¦æ•°
                pred_theta_deg = pred_theta_norm * 90
                pred_phi_deg = pred_phi_norm * 180
                
                # ç›®æ ‡è§’åº¦ï¼ˆä½¿ç”¨æœ€åæ—¶é—´æ­¥ï¼‰
                target_theta_norm = theta_label[:, -1].cpu().numpy()
                target_phi_norm = phi_label[:, -1].cpu().numpy()
                
                target_theta_deg = target_theta_norm * 90
                target_phi_deg = target_phi_norm * 180
                
                # è®¡ç®—è§’åº¦è¯¯å·®
                theta_error = np.abs(pred_theta_deg - target_theta_deg)
                phi_error = np.abs(pred_phi_deg - target_phi_deg)
                
                # å¤„ç†phiè§’åº¦çš„å‘¨æœŸæ€§
                phi_error = np.minimum(phi_error, 360 - phi_error)
                
                total_error = theta_error + phi_error
                angle_errors.extend(total_error)
                
                for i in range(len(pred_angles)):
                    all_predictions.append({
                        'predicted_theta': pred_theta_deg[i],
                        'predicted_phi': pred_phi_deg[i],
                        'target_theta': target_theta_deg[i],
                        'target_phi': target_phi_deg[i],
                        'theta_error': theta_error[i],
                        'phi_error': phi_error[i],
                        'total_error': total_error[i]
                    })
                    
            except Exception as e:
                print(f"æµ‹è¯•æ‰¹æ¬¡é”™è¯¯: {e}")
                continue
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if len(angle_errors) > 0:
        mean_error = np.mean(angle_errors)
        std_error = np.std(angle_errors)
        median_error = np.median(angle_errors)
        
        print(f"\nğŸ“Š é«˜çº§æ¨¡å‹æµ‹è¯•ç»“æœ:")
        print(f"å¹³å‡è§’åº¦è¯¯å·®: {mean_error:.3f}Â°")
        print(f"è§’åº¦è¯¯å·®æ ‡å‡†å·®: {std_error:.3f}Â°")
        print(f"è§’åº¦è¯¯å·®ä¸­ä½æ•°: {median_error:.3f}Â°")
        print(f"æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(all_predictions)}")
        
        if len(all_predictions) > 0:
            theta_errors = [p['theta_error'] for p in all_predictions]
            phi_errors = [p['phi_error'] for p in all_predictions]
            print(f"Î¸è¯¯å·®: {np.mean(theta_errors):.3f}Â° Â± {np.std(theta_errors):.3f}Â°")
            print(f"Ï†è¯¯å·®: {np.mean(phi_errors):.3f}Â° Â± {np.std(phi_errors):.3f}Â°")
            
            # è¯¯å·®åˆ†å¸ƒç»Ÿè®¡
            errors_below_1 = sum(1 for e in angle_errors if e < 1.0)
            errors_below_2 = sum(1 for e in angle_errors if e < 2.0)
            errors_below_5 = sum(1 for e in angle_errors if e < 5.0)
            
            total = len(angle_errors)
            print(f"è¯¯å·® < 1Â°: {errors_below_1}/{total} ({errors_below_1/total*100:.1f}%)")
            print(f"è¯¯å·® < 2Â°: {errors_below_2}/{total} ({errors_below_2/total*100:.1f}%)")
            print(f"è¯¯å·® < 5Â°: {errors_below_5}/{total} ({errors_below_5/total*100:.1f}%)")
    else:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
    
    return all_predictions

def main():
    """ä¸»å‡½æ•°"""
    warnings.filterwarnings('ignore', category=UserWarning)
    
    # æ£€æµ‹GPUç¯å¢ƒå’Œåˆ†å¸ƒå¼è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    gpu_count = torch.cuda.device_count()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿è¡Œ
    is_distributed_env = 'WORLD_SIZE' in os.environ
    use_distributed = is_distributed_env and gpu_count > 1
    
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"GPUå¯ç”¨: {torch.cuda.is_available()}")
    print(f"GPUæ•°é‡: {gpu_count}")
    print(f"åˆ†å¸ƒå¼ç¯å¢ƒ: {is_distributed_env}")
    print(f"ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ: {use_distributed}")
    
    if torch.cuda.is_available():
        print(f"ä¸»GPUå‹å·: {torch.cuda.get_device_name()}")
        print(f"ä¸»GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        if use_distributed:
            print(f"å°†ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ")
        elif gpu_count > 1:
            print(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œä½†æœªåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿è¡Œï¼Œå°†ä½¿ç”¨å•GPUè®­ç»ƒ")
            print("æç¤º: ä½¿ç”¨ 'python -m torch.distributed.launch --nproc_per_node={} advanced_beamforming_model.py' å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ".format(gpu_count))
    
    # æ•°æ®è·¯å¾„
    channel_folder = "samples_data/channel_data_opt_20250702_143327"
    angle_folder = "samples_data/angle_data_opt_20250702_143327"
    
    print("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆå¼€å¯æ•°æ®å¢å¼ºï¼‰
    dataset = BeamformingDataset(channel_folder, angle_folder, use_augmentation=True)
    
    # æŒ‰è¦æ±‚åˆ’åˆ†æ•°æ®é›†
    total_samples = len(dataset)
    train_size = 800
    test_size = total_samples - train_size
    
    indices = list(range(total_samples))
    np.random.seed(42)
    np.random.shuffle(indices)
    
    train_indices = indices[:train_size]
    test_indices = indices[train_size:]
    
    # ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†éªŒè¯é›†
    val_size = int(train_size * 0.20)  # 20%ä½œä¸ºéªŒè¯é›†
    train_final_indices = train_indices[val_size:]
    val_indices = train_indices[:val_size]
    
    print(f"é«˜çº§æ¨¡å‹æ•°æ®é›†åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_final_indices)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_indices)} æ ·æœ¬") 
    print(f"  æµ‹è¯•é›†: {len(test_indices)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®å­é›†
    train_dataset = torch.utils.data.Subset(dataset, train_final_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    test_dataset = torch.utils.data.Subset(dataset, test_indices)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - æ ¹æ®æ˜¯å¦åˆ†å¸ƒå¼æ¥å†³å®šsampler
    batch_size = 4  # å‡å°æ‰¹æ¬¡å¤§å°é€‚é…æ›´å¤§æ¨¡å‹
    
    # åªåœ¨çœŸæ­£çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­åˆ›å»ºDistributedSampler
    train_sampler = None
    val_sampler = None
    test_sampler = None
    
    if use_distributed:
        # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
        world_size, rank, local_rank = setup_distributed()
        if dist.is_initialized():
            train_sampler = DistributedSampler(train_dataset)
            val_sampler = DistributedSampler(val_dataset, shuffle=False)
            test_sampler = DistributedSampler(test_dataset, shuffle=False)
            print(f"Rank {rank}: åˆ›å»ºåˆ†å¸ƒå¼sampler")
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=(train_sampler is None), 
        sampler=train_sampler,
        num_workers=4, 
        pin_memory=True, 
        drop_last=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        sampler=val_sampler,
        num_workers=4, 
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        sampler=test_sampler,
        num_workers=4, 
        pin_memory=True
    )
    
    # åˆ›å»ºé«˜çº§Transformeræ¨¡å‹
    model = AdvancedTransformerBeamformingNet(
        input_dim=256*256*2,
        d_model=1024,     # æ›´å¤§çš„æ¨¡å‹ç»´åº¦
        nhead=16,         # æ›´å¤šæ³¨æ„åŠ›å¤´
        num_layers=12,    # æ›´æ·±çš„ç½‘ç»œ
        dropout=0.1       # é€‚åº¦çš„dropout
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"é«˜çº§æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,} ({total_params/1e6:.1f}M)")
    
    # è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ å¼€å§‹é«˜çº§æ¨¡å‹è®­ç»ƒ...")
    train_losses, val_losses = train_advanced_model(
        model, train_loader, val_loader, 
        num_epochs=200,
        lr=2e-4,
        device=device,
        use_distributed=use_distributed
    )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if os.path.exists('best_advanced_beamforming_model.pth'):
        model.load_state_dict(torch.load('best_advanced_beamforming_model.pth'))
        print("âœ“ åŠ è½½æœ€ä½³é«˜çº§æ¨¡å‹å®Œæˆ")
    
    # æµ‹è¯•æ¨¡å‹
    print("\nğŸ§ª å¼€å§‹é«˜çº§æ¨¡å‹æµ‹è¯•...")
    predictions = test_advanced_model(model, test_loader, device=device)
    
    # ç»˜åˆ¶ç»“æœ
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    
    # è®­ç»ƒæŸå¤±æ›²çº¿
    axes[0, 0].plot(train_losses, label='Training Loss', alpha=0.8, linewidth=2)
    axes[0, 0].plot(val_losses, label='Validation Loss', alpha=0.8, linewidth=2)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('Advanced Model Training Progress')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].set_yscale('log')
    
    if len(predictions) > 0:
        pred_theta = [p['predicted_theta'] for p in predictions]
        target_theta = [p['target_theta'] for p in predictions]
        pred_phi = [p['predicted_phi'] for p in predictions]
        target_phi = [p['target_phi'] for p in predictions]
        
        # Î¸è§’åº¦é¢„æµ‹
        axes[0, 1].scatter(target_theta, pred_theta, alpha=0.6, s=25, c='blue')
        min_theta = min(min(target_theta), min(pred_theta))
        max_theta = max(max(target_theta), max(pred_theta))
        axes[0, 1].plot([min_theta, max_theta], [min_theta, max_theta], 'r--', label='Perfect', linewidth=2)
        axes[0, 1].set_xlabel('True Î¸ (degrees)')
        axes[0, 1].set_ylabel('Predicted Î¸ (degrees)')
        axes[0, 1].set_title('Î¸ Angle Prediction (Advanced)')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Ï†è§’åº¦é¢„æµ‹
        axes[0, 2].scatter(target_phi, pred_phi, alpha=0.6, s=25, c='green')
        min_phi = min(min(target_phi), min(pred_phi))
        max_phi = max(max(target_phi), max(pred_phi))
        axes[0, 2].plot([min_phi, max_phi], [min_phi, max_phi], 'r--', label='Perfect', linewidth=2)
        axes[0, 2].set_xlabel('True Ï† (degrees)')
        axes[0, 2].set_ylabel('Predicted Ï† (degrees)')
        axes[0, 2].set_title('Ï† Angle Prediction (Advanced)')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # è¯¯å·®åˆ†å¸ƒ
        errors = [p['total_error'] for p in predictions]
        axes[1, 0].hist(errors, bins=40, alpha=0.7, edgecolor='black', color='orange')
        axes[1, 0].axvline(np.mean(errors), color='red', linestyle='--', linewidth=2,
                          label=f'Mean: {np.mean(errors):.2f}Â°')
        axes[1, 0].axvline(np.median(errors), color='blue', linestyle='--', linewidth=2,
                          label=f'Median: {np.median(errors):.2f}Â°')
        axes[1, 0].set_xlabel('Total Angle Error (degrees)')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].set_title('Error Distribution (Advanced)')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # Î¸å’ŒÏ†è¯¯å·®å¯¹æ¯”
        theta_errors = [p['theta_error'] for p in predictions]
        phi_errors = [p['phi_error'] for p in predictions]
        
        x_pos = [1, 2]
        error_means = [np.mean(theta_errors), np.mean(phi_errors)]
        error_stds = [np.std(theta_errors), np.std(phi_errors)]
        
        axes[1, 1].bar(x_pos, error_means, yerr=error_stds, capsize=5, 
                      color=['skyblue', 'lightcoral'], alpha=0.8)
        axes[1, 1].set_xticks(x_pos)
        axes[1, 1].set_xticklabels(['Î¸ Error', 'Ï† Error'])
        axes[1, 1].set_ylabel('Mean Error (degrees)')
        axes[1, 1].set_title('Î¸ vs Ï† Error Comparison')
        axes[1, 1].grid(True, alpha=0.3)
        
        # ç´¯ç§¯è¯¯å·®åˆ†å¸ƒ
        sorted_errors = np.sort(errors)
        cumulative_prob = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
        axes[1, 2].plot(sorted_errors, cumulative_prob * 100, linewidth=2, color='purple')
        axes[1, 2].axvline(np.percentile(sorted_errors, 90), color='red', linestyle='--',
                          label=f'90%: {np.percentile(sorted_errors, 90):.2f}Â°')
        axes[1, 2].axvline(np.percentile(sorted_errors, 95), color='orange', linestyle='--',
                          label=f'95%: {np.percentile(sorted_errors, 95):.2f}Â°')
        axes[1, 2].set_xlabel('Total Angle Error (degrees)')
        axes[1, 2].set_ylabel('Cumulative Probability (%)')
        axes[1, 2].set_title('Cumulative Error Distribution')
        axes[1, 2].legend()
        axes[1, 2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('advanced_training_results.png', dpi=300, bbox_inches='tight')
    print(f"\nğŸ“ˆ é«˜çº§æ¨¡å‹è®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º 'advanced_training_results.png'")
    
    # æ‰“å°è®­ç»ƒæ€»ç»“
    print(f"\nğŸ“‹ é«˜çº§æ¨¡å‹è®­ç»ƒæ€»ç»“:")
    if train_losses:
        print(f"â€¢ æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")
        print(f"â€¢ æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.6f}")
        print(f"â€¢ æ€»è®­ç»ƒè½®æ•°: {len(train_losses)}")
        print(f"â€¢ æŸå¤±æ”¹å–„: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.1f}%")
        print(f"â€¢ æ¨¡å‹è§„æ¨¡: {total_params/1e6:.1f}M å‚æ•°")
    
    return model, predictions

if __name__ == "__main__":
    main()
