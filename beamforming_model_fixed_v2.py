import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.nn.parallel import DataParallel, DistributedDataParallel
import torch.distributed as dist
import torch.multiprocessing as mp
import numpy as np
import scipy.io as sio
import h5py
import os
import glob
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from torch.nn import TransformerEncoder, TransformerEncoderLayer
import math
from tqdm import tqdm
import warnings

class BeamformingDataset(Dataset):
    """ä¿®å¤ç‰ˆå¤©çº¿é˜µåˆ—ä¿¡é“æ•°æ®é›†"""
    def __init__(self, channel_folder, angle_folder, transform=None):
        self.channel_folder = channel_folder
        self.angle_folder = angle_folder
        self.transform = transform
        
        # è·å–ä¿¡é“æ•°æ®æ–‡ä»¶åˆ—è¡¨å¹¶æ’åº
        self.channel_files = sorted(glob.glob(os.path.join(channel_folder, '*.mat')))
        print(f"æ‰¾åˆ°ä¿¡é“æ•°æ®æ–‡ä»¶: {len(self.channel_files)} ä¸ª")
        
        # åŠ è½½è§’åº¦æ•°æ®ï¼ˆæ‰€æœ‰æ ·æœ¬çš„è§’åº¦ä¿¡æ¯åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼‰
        angle_files = glob.glob(os.path.join(angle_folder, '*.mat'))
        if len(angle_files) > 0:
            try:
                # å°è¯•ä½¿ç”¨ h5py è¯»å–
                with h5py.File(angle_files[0], 'r') as f:
                    all_theta = np.array(f['all_theta'])  # (50, 1000) or (1000, 50)
                    all_phi = np.array(f['all_phi'])      # (50, 1000) or (1000, 50)
                    
                    # æ£€æŸ¥ç»´åº¦å¹¶è°ƒæ•´
                    if all_theta.shape[0] == 50 and all_theta.shape[1] == 1000:
                        self.theta_array = all_theta.T  # (1000, 50)
                        self.phi_array = all_phi.T      # (1000, 50)
                    else:
                        self.theta_array = all_theta    # å‡è®¾å·²ç»æ˜¯(1000, 50)
                        self.phi_array = all_phi
                    
                    self.num_samples = self.theta_array.shape[0]
                    self.num_time_samples = self.theta_array.shape[1]
                    
                    print(f"è§’åº¦æ•°æ®å½¢çŠ¶: theta={self.theta_array.shape}, phi={self.phi_array.shape}")
                    
            except Exception as e:
                print(f"h5py è¯»å–å¤±è´¥: {e}")
                # ä½¿ç”¨ scipy.io è¯»å–
                try:
                    angle_data = sio.loadmat(angle_files[0])
                    # æ£€æŸ¥å¯èƒ½çš„é”®å
                    possible_keys = ['all_theta', 'theta_array', 'theta']
                    theta_key = None
                    phi_key = None
                    
                    for key in angle_data.keys():
                        if 'theta' in key.lower():
                            theta_key = key
                        if 'phi' in key.lower():
                            phi_key = key
                    
                    if theta_key and phi_key:
                        all_theta = angle_data[theta_key]
                        all_phi = angle_data[phi_key]
                        
                        if all_theta.shape[0] == 50 and all_theta.shape[1] == 1000:
                            self.theta_array = all_theta.T
                            self.phi_array = all_phi.T
                        else:
                            self.theta_array = all_theta
                            self.phi_array = all_phi
                            
                        self.num_samples = self.theta_array.shape[0]
                        self.num_time_samples = self.theta_array.shape[1]
                    else:
                        raise ValueError("æœªæ‰¾åˆ°thetaå’Œphiæ•°æ®")
                        
                except Exception as e2:
                    print(f"scipy.io è¯»å–ä¹Ÿå¤±è´¥: {e2}")
                    print(f"è§’åº¦æ–‡ä»¶å†…å®¹: {list(angle_data.keys()) if 'angle_data' in locals() else 'Unknown'}")
                    raise e2
        
        # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼Œä½¿ç”¨è¾ƒå°çš„æ•°é‡
        self.actual_num_samples = min(len(self.channel_files), self.num_samples)
        print(f"å®é™…ä½¿ç”¨çš„æ ·æœ¬æ•°é‡: {self.actual_num_samples}")
        
    def __len__(self):
        return self.actual_num_samples
    
    def __getitem__(self, idx):
        if idx >= self.actual_num_samples:
            raise IndexError(f"ç´¢å¼• {idx} è¶…å‡ºèŒƒå›´ {self.actual_num_samples}")
            
        # åŠ è½½ä¿¡é“æ•°æ®
        try:
            # å°è¯•ä½¿ç”¨ h5py è¯»å–
            with h5py.File(self.channel_files[idx], 'r') as f:
                H_real = np.array(f['H_real'])  # (50, 256, 256)
                H_imag = np.array(f['H_imag'])  # (50, 256, 256)
                
                # è½¬ç½®ä»¥åŒ¹é…é¢„æœŸæ ¼å¼ [256, 256, 50]
                H_real = H_real.transpose(1, 2, 0)  # (256, 256, 50)
                H_imag = H_imag.transpose(1, 2, 0)  # (256, 256, 50)
                
        except Exception as e:
            # ä½¿ç”¨ scipy.io è¯»å–
            try:
                channel_data = sio.loadmat(self.channel_files[idx])
                H_real = channel_data['H_real']  # [256, 256, 50]
                H_imag = channel_data['H_imag']
            except Exception as e2:
                print(f"æ— æ³•è¯»å–ä¿¡é“æ•°æ®æ–‡ä»¶ {self.channel_files[idx]}: {e2}")
                raise e2
        
        # ç»„åˆå®éƒ¨å’Œè™šéƒ¨
        H_complex = H_real + 1j * H_imag
        
        # æ”¹è¿›çš„æ•°æ®å½’ä¸€åŒ–ï¼ˆé¿å…æå€¼ï¼‰
        H_real_std = np.std(H_real)
        H_imag_std = np.std(H_imag)
        
        if H_real_std > 1e-8:
            H_real_norm = (H_real - np.mean(H_real)) / H_real_std
        else:
            H_real_norm = H_real
            
        if H_imag_std > 1e-8:
            H_imag_norm = (H_imag - np.mean(H_imag)) / H_imag_std
        else:
            H_imag_norm = H_imag
        
        # è£å‰ªæå€¼ä»¥é¿å…æ¢¯åº¦çˆ†ç‚¸
        H_real_norm = np.clip(H_real_norm, -10, 10)
        H_imag_norm = np.clip(H_imag_norm, -10, 10)
        
        # è½¬æ¢ä¸ºPyTorch tensor
        H_input = np.stack([H_real_norm, H_imag_norm], axis=0)  # [2, 256, 256, 50]
        H_input = torch.FloatTensor(H_input)
        
        # æ”¹è¿›çš„è§’åº¦æ ‡ç­¾å½’ä¸€åŒ–
        theta_rad = self.theta_array[idx] * np.pi / 180  # è½¬æ¢ä¸ºå¼§åº¦
        phi_rad = self.phi_array[idx] * np.pi / 180
        
        # ä½¿ç”¨æ›´ç¨³å®šçš„å½’ä¸€åŒ–æ–¹å¼
        theta_norm = theta_rad / (np.pi / 2)  # å½’ä¸€åŒ–åˆ°[-2, 2]èŒƒå›´ï¼Œç„¶åè£å‰ª
        phi_norm = phi_rad / np.pi  # å½’ä¸€åŒ–åˆ°[-1, 1]
        
        theta_norm = np.clip(theta_norm, -1, 1)
        phi_norm = np.clip(phi_norm, -1, 1)
        
        theta_label = torch.FloatTensor(theta_norm)  # [50]
        phi_label = torch.FloatTensor(phi_norm)      # [50]
        
        return H_input, theta_label, phi_label, H_complex

class MultiScaleFeatureExtractor(nn.Module):
    """å¤šå°ºåº¦ç‰¹å¾æå–å™¨ï¼Œå¢å¼ºç©ºé—´-æ—¶é—´ç‰¹å¾è¡¨è¾¾"""
    def __init__(self, input_channels=2, d_model=1024):
        super().__init__()
        
        # 3Då·ç§¯åˆ†æ”¯ - æ•è·ç©ºé—´-æ—¶é—´ç›¸å…³æ€§
        self.conv3d_branch = nn.Sequential(
            nn.Conv3d(input_channels, 64, kernel_size=(3,3,3), padding=(1,1,1)),
            nn.BatchNorm3d(64),
            nn.GELU(),
            nn.Conv3d(64, 128, kernel_size=(3,3,3), padding=(1,1,1)),
            nn.BatchNorm3d(128),
            nn.GELU(),
            nn.MaxPool3d((2,2,1)),  # ç©ºé—´é™é‡‡æ ·ï¼Œä¿æŒæ—¶é—´ç»´åº¦
            
            nn.Conv3d(128, 256, kernel_size=(3,3,3), padding=(1,1,1)),
            nn.BatchNorm3d(256),
            nn.GELU(),
            nn.Conv3d(256, 512, kernel_size=(3,3,3), padding=(1,1,1)),
            nn.BatchNorm3d(512),
            nn.GELU(),
            nn.AdaptiveAvgPool3d((1, 1, 50)),  # å…¨å±€ç©ºé—´æ± åŒ–
        )
        
        # å¤šå°ºåº¦2Då·ç§¯åˆ†æ”¯
        self.multiscale_2d = nn.ModuleList([
            # å°å°ºåº¦ç‰¹å¾
            nn.Sequential(
                nn.Conv2d(input_channels, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.GELU(),
                nn.Conv2d(128, 256, 3, padding=1),
                nn.BatchNorm2d(256),
                nn.GELU(),
                nn.AdaptiveAvgPool2d(1)
            ),
            # ä¸­å°ºåº¦ç‰¹å¾
            nn.Sequential(
                nn.Conv2d(input_channels, 128, 5, padding=2),
                nn.BatchNorm2d(128),
                nn.GELU(),
                nn.Conv2d(128, 256, 5, padding=2),
                nn.BatchNorm2d(256),
                nn.GELU(),
                nn.AdaptiveAvgPool2d(1)
            ),
            # å¤§å°ºåº¦ç‰¹å¾
            nn.Sequential(
                nn.Conv2d(input_channels, 128, 7, padding=3),
                nn.BatchNorm2d(128),
                nn.GELU(),
                nn.Conv2d(128, 256, 7, padding=3),
                nn.BatchNorm2d(256),
                nn.GELU(),
                nn.AdaptiveAvgPool2d(1)
            )
        ])
        
        # ç‰¹å¾èåˆç½‘ç»œ
        total_features = 512 + 256 * 3  # 3Dç‰¹å¾ + 3ä¸ª2Dåˆ†æ”¯
        self.feature_fusion = nn.Sequential(
            nn.Linear(total_features, d_model * 2),
            nn.LayerNorm(d_model * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(d_model * 2, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
        )
        
    def forward(self, x):
        batch, channels, height, width, time = x.shape
        
        # 3Då·ç§¯åˆ†æ”¯
        conv3d_out = self.conv3d_branch(x)  # [batch, 512, 1, 1, 50]
        conv3d_features = conv3d_out.squeeze(2).squeeze(2)  # [batch, 512, 50]
        
        # å¤šå°ºåº¦2Då·ç§¯åˆ†æ”¯
        multiscale_features = []
        for t in range(time):
            frame = x[:, :, :, :, t]  # [batch, 2, 256, 256]
            frame_features = []
            for conv2d in self.multiscale_2d:
                feature = conv2d(frame).squeeze(-1).squeeze(-1)  # [batch, 256]
                frame_features.append(feature)
            multiscale_features.append(torch.cat(frame_features, dim=-1))  # [batch, 768]
        
        multiscale_features = torch.stack(multiscale_features, dim=1)  # [batch, 50, 768]
        
        # ç‰¹å¾èåˆ
        combined_features = []
        for t in range(time):
            conv3d_t = conv3d_features[:, :, t]  # [batch, 512]
            multiscale_t = multiscale_features[:, t, :]  # [batch, 768]
            combined_t = torch.cat([conv3d_t, multiscale_t], dim=-1)  # [batch, 1280]
            fused_t = self.feature_fusion(combined_t)  # [batch, d_model]
            combined_features.append(fused_t)
        
        return torch.stack(combined_features, dim=1)  # [batch, 50, d_model]

class EnhancedTransformerBlock(nn.Module):
    """å¢å¼ºçš„Transformerå—ï¼ŒåŠ å…¥æ›´å¤šéçº¿æ€§å’Œæ®‹å·®è¿æ¥"""
    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):
        super().__init__()
        
        # å¤šå¤´è‡ªæ³¨æ„åŠ›
        self.self_attn = nn.MultiheadAttention(
            d_model, nhead, dropout=dropout, batch_first=True
        )
        
        # å¢å¼ºçš„å‰é¦ˆç½‘ç»œ
        self.enhanced_ffn = nn.Sequential(
            nn.Linear(d_model, dim_feedforward),
            nn.LayerNorm(dim_feedforward),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward, dim_feedforward),
            nn.LayerNorm(dim_feedforward),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward, d_model),
        )
        
        # é—¨æ§çº¿æ€§å•å…ƒ
        self.glu = nn.Sequential(
            nn.Linear(d_model, d_model * 2),
            nn.GLU(dim=-1)
        )
        
        # å±‚å½’ä¸€åŒ–
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # Pre-LNè‡ªæ³¨æ„åŠ›
        residual = x
        x = self.norm1(x)
        attn_out, _ = self.self_attn(x, x, x)
        x = residual + self.dropout(attn_out)
        
        # Pre-LNå‰é¦ˆç½‘ç»œ
        residual = x
        x = self.norm2(x)
        ffn_out = self.enhanced_ffn(x)
        x = residual + self.dropout(ffn_out)
        
        # é—¨æ§çº¿æ€§å•å…ƒ
        residual = x
        x = self.norm3(x)
        glu_out = self.glu(x)
        x = residual + self.dropout(glu_out)
        
        return x

class HierarchicalAttentionPooling(nn.Module):
    """åˆ†å±‚æ³¨æ„åŠ›æ± åŒ–ï¼Œä»å±€éƒ¨åˆ°å…¨å±€èšåˆä¿¡æ¯"""
    def __init__(self, d_model, nhead=8):
        super().__init__()
        
        # å±€éƒ¨æ³¨æ„åŠ›ï¼ˆç›¸é‚»æ—¶é—´æ­¥ï¼‰
        self.local_attn = nn.MultiheadAttention(
            d_model, nhead, batch_first=True
        )
        
        # å…¨å±€æ³¨æ„åŠ›
        self.global_attn = nn.MultiheadAttention(
            d_model, nhead, batch_first=True
        )
        
        # å¯å­¦ä¹ æŸ¥è¯¢å‘é‡
        self.local_query = nn.Parameter(torch.randn(1, 1, d_model))
        self.global_query = nn.Parameter(torch.randn(1, 1, d_model))
        
        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Linear(d_model * 2, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
    def forward(self, x):
        batch_size = x.size(0)
        
        # å±€éƒ¨æ³¨æ„åŠ›èšåˆ
        local_query = self.local_query.expand(batch_size, -1, -1)
        local_out, _ = self.local_attn(local_query, x, x)
        
        # å…¨å±€æ³¨æ„åŠ›èšåˆ
        global_query = self.global_query.expand(batch_size, -1, -1)
        global_out, _ = self.global_attn(global_query, x, x)
        
        # èåˆå±€éƒ¨å’Œå…¨å±€ç‰¹å¾
        combined = torch.cat([local_out.squeeze(1), global_out.squeeze(1)], dim=-1)
        fused = self.fusion(combined)
        
        return fused

class AdvancedAnglePredictor(nn.Module):
    """é«˜çº§è§’åº¦é¢„æµ‹å™¨ï¼ŒåŒ…å«å¤šä¸ªé¢„æµ‹å¤´å’Œé›†æˆ"""
    def __init__(self, d_model, dropout=0.1):
        super().__init__()
        
        # æ·±åº¦ç‰¹å¾æå–
        self.feature_extractor = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        
        # å¤šä¸ªä¸“é—¨çš„é¢„æµ‹å¤´
        self.theta_predictor = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model // 4),
            nn.LayerNorm(d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 4, 64),
            nn.GELU(),
            nn.Linear(64, 1)
        )
        
        self.phi_predictor = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model // 4),
            nn.LayerNorm(d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 4, 64),
            nn.GELU(),
            nn.Linear(64, 1)
        )
        
        # è”åˆé¢„æµ‹å¤´ï¼ˆç”¨äºé›†æˆï¼‰
        self.joint_predictor = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model // 4),
            nn.LayerNorm(d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 4, 64),
            nn.GELU(),
            nn.Linear(64, 2)
        )
        
        # é›†æˆæƒé‡
        self.ensemble_weights = nn.Parameter(torch.ones(2))
        
    def forward(self, x):
        # ç‰¹å¾æå–
        features = self.feature_extractor(x)
        
        # ç‹¬ç«‹é¢„æµ‹
        theta_pred = self.theta_predictor(features)
        phi_pred = self.phi_predictor(features)
        independent_pred = torch.cat([theta_pred, phi_pred], dim=-1)
        
        # è”åˆé¢„æµ‹
        joint_pred = self.joint_predictor(features)
        
        # é›†æˆé¢„æµ‹ç»“æœ
        weights = F.softmax(self.ensemble_weights, dim=0)
        final_pred = weights[0] * independent_pred + weights[1] * joint_pred
        
        return final_pred

class UltraTransformerBeamformingNet(nn.Module):
    """è¶…å¼ºTransformeræ³¢æŸæˆå½¢ç½‘ç»œ"""
    def __init__(self, d_model=1024, nhead=16, num_layers=12, dropout=0.1):
        super().__init__()
        
        self.d_model = d_model
        
        # å¤šå°ºåº¦ç‰¹å¾æå–å™¨
        self.feature_extractor = MultiScaleFeatureExtractor(
            input_channels=2, d_model=d_model
        )
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model, max_len=100)
        
        # å¤šä¸ªå¢å¼ºTransformerå—
        self.transformer_blocks = nn.ModuleList([
            EnhancedTransformerBlock(
                d_model=d_model,
                nhead=nhead,
                dim_feedforward=d_model * 4,
                dropout=dropout
            ) for _ in range(num_layers)
        ])
        
        # åˆ†å±‚æ³¨æ„åŠ›æ± åŒ–
        self.hierarchical_pooling = HierarchicalAttentionPooling(
            d_model=d_model, nhead=nhead
        )
        
        # é«˜çº§è§’åº¦é¢„æµ‹å™¨
        self.angle_predictor = AdvancedAnglePredictor(
            d_model=d_model, dropout=dropout
        )
        
        # æƒé‡åˆå§‹åŒ–
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            nn.init.xavier_normal_(module.weight, gain=1.0)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
            nn.init.constant_(module.bias, 0)
            nn.init.constant_(module.weight, 1.0)
        elif isinstance(module, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
    
    def forward(self, x):
        # å¤šå°ºåº¦ç‰¹å¾æå–
        x = self.feature_extractor(x)  # [batch, 50, d_model]
        
        # ä½ç½®ç¼–ç 
        x = x * math.sqrt(self.d_model)
        x = x.transpose(0, 1)  # [50, batch, d_model]
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)  # [batch, 50, d_model]
        
        # å¤šå±‚å¢å¼ºTransformer
        for transformer_block in self.transformer_blocks:
            x = transformer_block(x)
        
        # åˆ†å±‚æ³¨æ„åŠ›æ± åŒ–
        aggregated = self.hierarchical_pooling(x)  # [batch, d_model]
        
        # è§’åº¦é¢„æµ‹
        angles = self.angle_predictor(aggregated)  # [batch, 2]
        
        return angles

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
        
    def forward(self, x):
        return x + self.pe[:x.size(0), :]

class TransformerBeamformingNet(nn.Module):
    """åŸºäºTransformerçš„æ³¢æŸæˆå½¢ç½‘ç»œï¼Œæå‡è§’åº¦é¢„æµ‹ç²¾åº¦"""
    def __init__(self, input_dim=256*256*2, d_model=768, nhead=12, num_layers=8, dropout=0.15):
        super(TransformerBeamformingNet, self).__init__()
        
        self.d_model = d_model
        
        # é«˜æ•ˆçš„ç‰¹å¾æå–å™¨ï¼ˆä½¿ç”¨å·ç§¯é™ç»´ï¼‰
        self.feature_extractor = nn.Sequential(
            # å…ˆç”¨å·ç§¯é™ç»´å‡å°‘è®¡ç®—é‡
            nn.Conv1d(input_dim, d_model * 2, kernel_size=1),
            nn.BatchNorm1d(d_model * 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Conv1d(d_model * 2, d_model, kernel_size=1),
            nn.BatchNorm1d(d_model),
            nn.GELU(),
            nn.Dropout(dropout),
        )
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model, max_len=100)
        
        # æ›´å¼ºçš„Transformerç¼–ç å™¨
        encoder_layers = TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,  # æ›´å¤§çš„FFN
            dropout=dropout,
            activation='gelu',  # ä½¿ç”¨GELUæ¿€æ´»
            batch_first=True,
            norm_first=True  # Pre-LNæ¶æ„ï¼Œæ›´ç¨³å®š
        )
        self.transformer_encoder = TransformerEncoder(
            encoder_layers, 
            num_layers=num_layers,
            norm=nn.LayerNorm(d_model)
        )
        
        # å¤šå¤´æ³¨æ„åŠ›èšåˆï¼ˆæ›¿ä»£ç®€å•çš„æœ€åæ—¶é—´æ­¥ï¼‰
        self.attention_pooling = nn.MultiheadAttention(
            embed_dim=d_model,
            num_heads=nhead,
            dropout=dropout,
            batch_first=True
        )
        
        # æ”¹è¿›çš„è§’åº¦é¢„æµ‹å¤´ï¼ˆå¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        self.angle_predictor = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(dropout * 1.5),  # æ›´é«˜çš„dropout
            nn.Linear(d_model, d_model // 2),
            nn.LayerNorm(d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout * 1.2),
            nn.Linear(d_model // 2, d_model // 4),
            nn.LayerNorm(d_model // 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 4, 64),
            nn.GELU(),
            nn.Dropout(dropout * 0.5),  # è¾“å‡ºå±‚å‰è½»å¾®dropout
            nn.Linear(64, 2)  # theta, phi
        )
        
        # å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡ç”¨äºæ³¨æ„åŠ›èšåˆ
        self.query_vector = nn.Parameter(torch.randn(1, 1, d_model))
        
        # æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            # ä½¿ç”¨æ›´å¥½çš„åˆå§‹åŒ–
            nn.init.xavier_normal_(module.weight, gain=1.0)
            if module.bias is not None:
                nn.init.constant_(module.bias, 0)
        elif isinstance(module, (nn.LayerNorm, nn.BatchNorm1d)):
            nn.init.constant_(module.bias, 0)
            nn.init.constant_(module.weight, 1.0)
        elif isinstance(module, nn.Conv1d):
            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                    
    def forward(self, x):
        batch_size, channels, height, width, time_steps = x.shape
        
        # é‡å¡‘è¾“å…¥ [batch, time_steps, features]
        x = x.permute(0, 4, 1, 2, 3)  # [batch, time_steps, channels, height, width]
        x = x.reshape(batch_size, time_steps, -1)  # [batch, time_steps, features]
        
        # ç‰¹å¾æå–ï¼ˆä½¿ç”¨1Då·ç§¯ï¼‰
        x = x.permute(0, 2, 1)  # [batch, features, time_steps]
        x = self.feature_extractor(x)  # [batch, d_model, time_steps]
        x = x.permute(0, 2, 1)  # [batch, time_steps, d_model]
        
        # è¾“å…¥ç¼©æ”¾å’Œä½ç½®ç¼–ç 
        x = x * math.sqrt(self.d_model)
        x = x.transpose(0, 1)  # [time_steps, batch, d_model]
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)  # [batch, time_steps, d_model]
        
        # Transformerç¼–ç 
        encoded = self.transformer_encoder(x)  # [batch, time_steps, d_model]
        
        # æ³¨æ„åŠ›èšåˆï¼ˆæ›´å¥½çš„æ—¶åºä¿¡æ¯æ•´åˆï¼‰
        query = self.query_vector.expand(batch_size, -1, -1)  # [batch, 1, d_model]
        aggregated, attention_weights = self.attention_pooling(
            query, encoded, encoded
        )  # [batch, 1, d_model]
        aggregated = aggregated.squeeze(1)  # [batch, d_model]
        
        # è§’åº¦é¢„æµ‹
        angles = self.angle_predictor(aggregated)  # [batch, 2]
        
        return angles

def ultra_loss_function(predictions, targets, loss_type='ultra_focal'):
    """è¶…å¼ºæŸå¤±å‡½æ•°ï¼Œç»“åˆå¤šç§æŸå¤±ç­–ç•¥"""
    pred_angles = predictions
    target_theta, target_phi = targets
    
    target_theta_last = target_theta[:, -1]
    target_phi_last = target_phi[:, -1]
    
    if loss_type == 'ultra_focal':
        # è®¡ç®—åŸºç¡€è¯¯å·®
        theta_error = torch.abs(pred_angles[:, 0] - target_theta_last)
        phi_error = torch.abs(pred_angles[:, 1] - target_phi_last)
        
        # è‡ªé€‚åº”focalæƒé‡
        theta_focal = torch.pow(theta_error + 1e-8, 0.25)  # æ›´æ¸©å’Œçš„æƒé‡
        phi_focal = torch.pow(phi_error + 1e-8, 0.25)
        
        # ç»„åˆæŸå¤±ï¼šHuber + MSE + Smooth L1
        theta_huber = F.huber_loss(pred_angles[:, 0], target_theta_last, delta=0.1, reduction='none')
        phi_huber = F.huber_loss(pred_angles[:, 1], target_phi_last, delta=0.1, reduction='none')
        
        theta_mse = F.mse_loss(pred_angles[:, 0], target_theta_last, reduction='none')
        phi_mse = F.mse_loss(pred_angles[:, 1], target_phi_last, reduction='none')
        
        theta_smooth = F.smooth_l1_loss(pred_angles[:, 0], target_theta_last, reduction='none')
        phi_smooth = F.smooth_l1_loss(pred_angles[:, 1], target_phi_last, reduction='none')
        
        # åŠ æƒç»„åˆ
        theta_loss = theta_focal * (0.4 * theta_huber + 0.3 * theta_mse + 0.3 * theta_smooth)
        phi_loss = phi_focal * (0.4 * phi_huber + 0.3 * phi_mse + 0.3 * phi_smooth)
        
        theta_loss = theta_loss.mean()
        phi_loss = phi_loss.mean()
        
        # è§’åº¦ä¸€è‡´æ€§æŸå¤±
        angle_consistency = F.mse_loss(
            torch.norm(pred_angles, dim=1),
            torch.norm(torch.stack([target_theta_last, target_phi_last], dim=1), dim=1)
        )
        
        total_loss = theta_loss + phi_loss + 0.1 * angle_consistency
        
    else:
        # å›é€€åˆ°æ ‡å‡†æŸå¤±
        theta_loss = F.huber_loss(pred_angles[:, 0], target_theta_last, delta=1.0)
        phi_loss = F.huber_loss(pred_angles[:, 1], target_phi_last, delta=1.0)
        total_loss = theta_loss + phi_loss
        
    # ç¡®ä¿æŸå¤±å€¼åœ¨åˆç†èŒƒå›´å†…
    total_loss = torch.clamp(total_loss, 0, 50)
    
    return total_loss, theta_loss, phi_loss

def create_enhanced_model():
    """åˆ›å»ºå¢å¼ºæ¨¡å‹"""
    model = UltraTransformerBeamformingNet(
        d_model=512,    # å¢å¤§æ¨¡å‹ç»´åº¦
        nhead=16,        # å¢åŠ æ³¨æ„åŠ›å¤´æ•°
        num_layers=12,   # å¢åŠ å±‚æ•°
        dropout=0.1      # é€‚åº¦dropout
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"ğŸ”§ å¢å¼ºæ¨¡å‹åˆ›å»ºå®Œæˆ:")
    print(f"   â€¢ æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"   â€¢ å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   â€¢ æ¨¡å‹ç»´åº¦: {model.d_model}")
    print(f"   â€¢ æ³¨æ„åŠ›å¤´æ•°: 16")
    print(f"   â€¢ Transformerå±‚æ•°: 12")
    
    return model

def enhanced_train_model(model, train_loader, val_loader, num_epochs=200, lr=1e-4, device='cuda', use_multi_gpu=True):
    """å¢å¼ºè®­ç»ƒå‡½æ•°ï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒ"""
    
    # åˆå§‹åŒ–GPUç›‘æ§å™¨
    gpu_monitor = GPUMonitor()
    gpu_monitor.reset()
    
    # ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
    optimize_memory_usage()
    
    # è®¾ç½®å¤šGPUè®­ç»ƒ
    if use_multi_gpu and torch.cuda.device_count() > 1:
        model, device = setup_multi_gpu_model(model)
        effective_batch_size = train_loader.batch_size * torch.cuda.device_count()
        print(f"ğŸ”¥ å¤šGPUè®­ç»ƒ - æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size}")
    else:
        model.to(device)
        effective_batch_size = train_loader.batch_size
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¢«DataParallelåŒ…è£…
    is_multi_gpu = isinstance(model, DataParallel)
    
    # ä½¿ç”¨æ›´ä¿å®ˆçš„ä¼˜åŒ–å™¨è®¾ç½®ï¼ˆé€‚åº”å¤æ‚æ¨¡å‹ï¼‰
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=lr, 
        weight_decay=1e-4,  # é€‚åº¦æ­£åˆ™åŒ–
        eps=1e-8,
        betas=(0.9, 0.95)  # æ›´ä¿å®ˆçš„momentum
    )
    
    # ä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=20,  # æ¯20ä¸ªepoché‡å¯ä¸€æ¬¡
        T_mult=2,  # æ¯æ¬¡é‡å¯æ—¶å‘¨æœŸç¿»å€
        eta_min=lr/100  # æœ€å°å­¦ä¹ ç‡
    )
    
    # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜å’ŒåŠ é€Ÿï¼‰
    scaler = torch.cuda.amp.GradScaler() if device != 'cpu' else None
    use_amp = scaler is not None
    
    # æ¢¯åº¦ç´¯ç§¯å‚æ•°ï¼ˆæ ¹æ®GPUæ•°é‡è°ƒæ•´ï¼‰
    accumulation_steps = max(1, 4 // torch.cuda.device_count()) if torch.cuda.is_available() else 2
    
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 50
    min_improvement = 1e-6
    
    print(f"ğŸš€ å¼€å§‹å¢å¼ºæ¨¡å‹è®­ç»ƒ:")
    print(f"   â€¢ åˆå§‹å­¦ä¹ ç‡: {lr}")
    print(f"   â€¢ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
    print(f"   â€¢ æ—©åœè€å¿ƒå€¼: {early_stop_patience}")
    print(f"   â€¢ æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
    print(f"   â€¢ å¤šGPUè®­ç»ƒ: {'å¯ç”¨' if is_multi_gpu else 'ç¦ç”¨'}")
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_epoch = 0
        train_theta_loss = 0
        train_phi_loss = 0
        num_batches = 0
        
        train_progress = tqdm(train_loader, desc=f"ğŸ¯ è®­ç»ƒ Epoch {epoch+1}/{num_epochs}", leave=False)
        
        optimizer.zero_grad()  # åœ¨epochå¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
        
        for batch_idx, (H_input, theta_label, phi_label, H_complex) in enumerate(train_progress):
            try:
                H_input = H_input.to(device, non_blocking=True)
                theta_label = theta_label.to(device, non_blocking=True)
                phi_label = phi_label.to(device, non_blocking=True)
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§
                if torch.isnan(H_input).any() or torch.isinf(H_input).any():
                    print(f"âš ï¸ è¾“å…¥æ•°æ®åŒ…å«NaNæˆ–Infï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                    continue
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                if use_amp:
                    with torch.cuda.amp.autocast():
                        predictions = model(H_input)
                        loss, theta_loss, phi_loss = ultra_loss_function(
                            predictions, (theta_label, phi_label), loss_type='ultra_focal'
                        )
                        loss = loss / accumulation_steps
                else:
                    predictions = model(H_input)
                    loss, theta_loss, phi_loss = ultra_loss_function(
                        predictions, (theta_label, phi_label), loss_type='ultra_focal'
                    )
                    loss = loss / accumulation_steps
                
                # æ£€æŸ¥æŸå¤±çš„æœ‰æ•ˆæ€§
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"âš ï¸ æŸå¤±ä¸ºNaNæˆ–Infï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                    continue
                
                # åå‘ä¼ æ’­ï¼ˆç´¯ç§¯æ¢¯åº¦ï¼‰
                if use_amp:
                    scaler.scale(loss).backward()
                else:
                    loss.backward()
                
                # æ¯accumulation_stepsæ­¥æ‰§è¡Œä¸€æ¬¡ä¼˜åŒ–
                if (batch_idx + 1) % accumulation_steps == 0:
                    if use_amp:
                        # æ¢¯åº¦è£å‰ª
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        # æ¢¯åº¦è£å‰ª
                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                        optimizer.step()
                    
                    optimizer.zero_grad()
                
                train_loss_epoch += loss.item() * accumulation_steps
                train_theta_loss += theta_loss.item()
                train_phi_loss += phi_loss.item()
                num_batches += 1
                
                # æ›´æ–°GPUç›‘æ§
                gpu_monitor.update()
                
                # æ›´æ–°è¿›åº¦æ¡
                current_lr = optimizer.param_groups[0]['lr']
                peak_memory = gpu_monitor.get_peak_memory()
                train_progress.set_postfix({
                    'Loss': f'{loss.item() * accumulation_steps:.4f}',
                    'Î¸': f'{theta_loss.item():.4f}',
                    'Ï†': f'{phi_loss.item():.4f}',
                    'LR': f'{current_lr:.2e}',
                    'GPU': f'{peak_memory:.1f}GB'
                })
                
                # å®šæœŸæ¸…ç†æ˜¾å­˜
                if batch_idx % 50 == 0:
                    torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        # å¤„ç†æœ€åçš„æ¢¯åº¦ç´¯ç§¯
        if num_batches % accumulation_steps != 0:
            if use_amp:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
            optimizer.zero_grad()
        
        scheduler.step()  # æ›´æ–°å­¦ä¹ ç‡
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_epoch = 0
        val_theta_loss = 0
        val_phi_loss = 0
        val_batches = 0
        
        with torch.no_grad():
            val_progress = tqdm(val_loader, desc="ğŸ” éªŒè¯", leave=False)
            for H_input, theta_label, phi_label, H_complex in val_progress:
                try:
                    H_input = H_input.to(device, non_blocking=True)
                    theta_label = theta_label.to(device, non_blocking=True)
                    phi_label = phi_label.to(device, non_blocking=True)
                    
                    if use_amp:
                        with torch.cuda.amp.autocast():
                            predictions = model(H_input)
                            loss, theta_loss, phi_loss = ultra_loss_function(
                                predictions, (theta_label, phi_label), loss_type='ultra_focal'
                            )
                    else:
                        predictions = model(H_input)
                        loss, theta_loss, phi_loss = ultra_loss_function(
                            predictions, (theta_label, phi_label), loss_type='ultra_focal'
                        )
                    
                    if not (torch.isnan(loss) or torch.isinf(loss)):
                        val_loss_epoch += loss.item()
                        val_theta_loss += theta_loss.item()
                        val_phi_loss += phi_loss.item()
                        val_batches += 1
                        
                except Exception as e:
                    continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        if num_batches > 0:
            train_loss_avg = train_loss_epoch / num_batches
            train_theta_avg = train_theta_loss / num_batches
            train_phi_avg = train_phi_loss / num_batches
        else:
            train_loss_avg = float('inf')
            train_theta_avg = float('inf')
            train_phi_avg = float('inf')
            
        if val_batches > 0:
            val_loss_avg = val_loss_epoch / val_batches
            val_theta_avg = val_theta_loss / val_batches
            val_phi_avg = val_phi_loss / val_batches
        else:
            val_loss_avg = float('inf')
            val_theta_avg = float('inf')
            val_phi_avg = float('inf')
        
        train_losses.append(train_loss_avg)
        val_losses.append(val_loss_avg)
        
        # åŠ¨æ€è°ƒæ•´æ—©åœç­–ç•¥
        current_early_stop_patience = early_stop_patience
        if val_loss_avg < 0.0001:  # å½“éªŒè¯æŸå¤±æä½æ—¶
            current_early_stop_patience = 80  # æ›´å¤§çš„patience
        elif val_loss_avg < 0.001:
            current_early_stop_patience = 60
        
        # æ‰“å°è¯¦ç»†çš„epochç»“æœ
        current_lr = optimizer.param_groups[0]['lr']
        train_val_gap = val_loss_avg - train_loss_avg
        peak_memory = gpu_monitor.get_peak_memory()
        
        # ä½¿ç”¨emojiå’Œé¢œè‰²çªå‡ºé‡è¦ä¿¡æ¯
        status_icon = "ğŸ”¥" if val_loss_avg < best_val_loss else "ğŸ“Š"
        print(f"{status_icon} Epoch {epoch+1:3d}: "
              f"Train={train_loss_avg:.6f} (Î¸:{train_theta_avg:.6f}, Ï†:{train_phi_avg:.6f}) | "
              f"Val={val_loss_avg:.6f} (Î¸:{val_theta_avg:.6f}, Ï†:{val_phi_avg:.6f}) | "
              f"Gap={train_val_gap:.6f} | LR={current_lr:.2e} | "
              f"GPU={peak_memory:.1f}GB | Patience={patience_counter}/{current_early_stop_patience}")
        
        # æ—©åœå’Œæ¨¡å‹ä¿å­˜
        improvement = best_val_loss - val_loss_avg
        if improvement > min_improvement:
            best_val_loss = val_loss_avg
            patience_counter = 0
            
            # ä¿å­˜æ¨¡å‹æ—¶éœ€è¦è€ƒè™‘DataParallel
            if is_multi_gpu:
                torch.save(model.module.state_dict(), 'best_ultra_beamforming_model.pth')
            else:
                torch.save(model.state_dict(), 'best_ultra_beamforming_model.pth')
            print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Loss: {val_loss_avg:.6f}, æ”¹è¿›: {improvement:.6f})")
        else:
            patience_counter += 1
            
        if patience_counter >= current_early_stop_patience:
            print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼åœ¨epoch {epoch+1}åœæ­¢è®­ç»ƒ (patience: {patience_counter}/{current_early_stop_patience})")
            break
        
        # å®šæœŸæ˜¾å­˜æ¸…ç†
        if epoch % 10 == 0:
            optimize_memory_usage()
    
    print(f"ğŸ è®­ç»ƒå®Œæˆï¼Œå³°å€¼æ˜¾å­˜ä½¿ç”¨: {gpu_monitor.get_peak_memory():.1f}GB")
    return train_losses, val_losses

def train_model(model, train_loader, val_loader, num_epochs=150, lr=3e-4, device='cuda', use_multi_gpu=True):
    """åŸå§‹è®­ç»ƒå‡½æ•°ï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒ"""
    
    # åˆå§‹åŒ–GPUç›‘æ§å™¨
    gpu_monitor = GPUMonitor()
    gpu_monitor.reset()
    
    # ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
    optimize_memory_usage()
    
    # è®¾ç½®å¤šGPUè®­ç»ƒ
    if use_multi_gpu and torch.cuda.device_count() > 1:
        model, device = setup_multi_gpu_model(model)
        effective_batch_size = train_loader.batch_size * torch.cuda.device_count()
        print(f"ğŸ”¥ å¤šGPUè®­ç»ƒ - æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch_size}")
    else:
        model.to(device)
        effective_batch_size = train_loader.batch_size
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¢«DataParallelåŒ…è£…
    is_multi_gpu = isinstance(model, DataParallel)
    
    # ä½¿ç”¨æ›´æ¿€è¿›çš„ä¼˜åŒ–å™¨è®¾ç½®
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=lr, 
        weight_decay=2e-4,  # å¢åŠ æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ
        eps=1e-8,
        betas=(0.9, 0.999)
    )
    
    # æ”¹è¿›çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=lr,
        epochs=num_epochs,
        steps_per_epoch=len(train_loader),
        pct_start=0.1,  # 10%æ—¶é—´warm-up
        div_factor=10,  # åˆå§‹lr = max_lr/10
        final_div_factor=100,  # æœ€ç»ˆlr = max_lr/100
        anneal_strategy='cos'
    )
    
    # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆèŠ‚çœæ˜¾å­˜å’ŒåŠ é€Ÿï¼‰
    scaler = torch.cuda.amp.GradScaler() if device != 'cpu' else None
    use_amp = scaler is not None
    
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 40  # å¢åŠ patienceï¼Œåœ¨ä½æŸå¤±æ—¶æ›´å®½å®¹
    min_improvement = 1e-5  # æœ€å°æ”¹è¿›é˜ˆå€¼ï¼Œé¿å…å¾®å°æ³¢åŠ¨è§¦å‘æ—©åœ
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œæœ€å¤§å­¦ä¹ ç‡: {lr}")
    print(f"   â€¢ æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if use_amp else 'ç¦ç”¨'}")
    print(f"   â€¢ å¤šGPUè®­ç»ƒ: {'å¯ç”¨' if is_multi_gpu else 'ç¦ç”¨'}")
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss_epoch = 0
        train_theta_loss = 0
        train_phi_loss = 0
        num_batches = 0
        
        train_progress = tqdm(train_loader, desc=f"è®­ç»ƒ Epoch {epoch+1}/{num_epochs}", leave=False)
        
        for batch_idx, (H_input, theta_label, phi_label, H_complex) in enumerate(train_progress):
            try:
                H_input = H_input.to(device, non_blocking=True)
                theta_label = theta_label.to(device, non_blocking=True)
                phi_label = phi_label.to(device, non_blocking=True)
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§
                if torch.isnan(H_input).any() or torch.isinf(H_input).any():
                    print(f"è­¦å‘Š: è¾“å…¥æ•°æ®åŒ…å«NaNæˆ–Infï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                    continue
                
                optimizer.zero_grad()
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                if use_amp:
                    with torch.cuda.amp.autocast():
                        predictions = model(H_input)
                        loss, theta_loss, phi_loss = improved_loss_function(
                            predictions, (theta_label, phi_label), loss_type='focal_huber'
                        )
                else:
                    predictions = model(H_input)
                    loss, theta_loss, phi_loss = improved_loss_function(
                        predictions, (theta_label, phi_label), loss_type='focal_huber'
                    )
                
                # æ£€æŸ¥æŸå¤±çš„æœ‰æ•ˆæ€§
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"è­¦å‘Š: æŸå¤±ä¸ºNaNæˆ–Infï¼Œè·³è¿‡æ‰¹æ¬¡ {batch_idx}")
                    continue
                
                # åå‘ä¼ æ’­
                if use_amp:
                    scaler.scale(loss).backward()
                    # æ¢¯åº¦è£å‰ªï¼ˆé€‚åº”æ›´é«˜å­¦ä¹ ç‡ï¼‰
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    loss.backward()
                    # æ¢¯åº¦è£å‰ªï¼ˆé€‚åº”æ›´é«˜å­¦ä¹ ç‡ï¼‰
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)
                    optimizer.step()
                
                scheduler.step()  # OneCycleLRéœ€è¦æ¯ä¸ªstepè°ƒç”¨
                
                train_loss_epoch += loss.item()
                train_theta_loss += theta_loss.item()
                train_phi_loss += phi_loss.item()
                num_batches += 1
                
                # æ›´æ–°GPUç›‘æ§
                gpu_monitor.update()
                
                # æ›´æ–°è¿›åº¦æ¡
                current_lr = optimizer.param_groups[0]['lr']
                peak_memory = gpu_monitor.get_peak_memory()
                train_progress.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Î¸': f'{theta_loss.item():.4f}',
                    'Ï†': f'{phi_loss.item():.4f}',
                    'LR': f'{current_lr:.2e}',
                    'GPU': f'{peak_memory:.1f}GB'
                })
                
                # å®šæœŸæ¸…ç†æ˜¾å­˜
                if batch_idx % 50 == 0:
                    torch.cuda.empty_cache()
                
            except Exception as e:
                print(f"è®­ç»ƒæ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss_epoch = 0
        val_theta_loss = 0
        val_phi_loss = 0
        val_batches = 0
        
        with torch.no_grad():
            val_progress = tqdm(val_loader, desc="éªŒè¯", leave=False)
            for H_input, theta_label, phi_label, H_complex in val_progress:
                try:
                    H_input = H_input.to(device, non_blocking=True)
                    theta_label = theta_label.to(device, non_blocking=True)
                    phi_label = phi_label.to(device, non_blocking=True)
                    
                    if use_amp:
                        with torch.cuda.amp.autocast():
                            predictions = model(H_input)
                            loss, theta_loss, phi_loss = improved_loss_function(
                                predictions, (theta_label, phi_label), loss_type='focal_huber'
                            )
                    else:
                        predictions = model(H_input)
                        loss, theta_loss, phi_loss = improved_loss_function(
                            predictions, (theta_label, phi_label), loss_type='focal_huber'
                        )
                    
                    if not (torch.isnan(loss) or torch.isinf(loss)):
                        val_loss_epoch += loss.item()
                        val_theta_loss += theta_loss.item()
                        val_phi_loss += phi_loss.item()
                        val_batches += 1
                        
                except Exception as e:
                    continue
        
        # è®¡ç®—å¹³å‡æŸå¤±
        if num_batches > 0:
            train_loss_avg = train_loss_epoch / num_batches
            train_theta_avg = train_theta_loss / num_batches
            train_phi_avg = train_phi_loss / num_batches
        else:
            train_loss_avg = float('inf')
            train_theta_avg = float('inf')
            train_phi_avg = float('inf')
            
        if val_batches > 0:
            val_loss_avg = val_loss_epoch / val_batches
            val_theta_avg = val_theta_loss / val_batches
            val_phi_avg = val_phi_loss / val_batches
        else:
            val_loss_avg = float('inf')
            val_theta_avg = float('inf')
            val_phi_avg = float('inf')
        
        train_losses.append(train_loss_avg)
        val_losses.append(val_loss_avg)
        
        # åœ¨æä½æŸå¤±æ—¶ä½¿ç”¨æ›´å®½æ¾çš„æ—©åœç­–ç•¥
        current_early_stop_patience = early_stop_patience
        if val_loss_avg < 0.001:  # å½“éªŒè¯æŸå¤±å¾ˆä½æ—¶
            current_early_stop_patience = 60  # æ›´å¤§çš„patience
        
        # æ‰“å°epochç»“æœ - å¢åŠ æ›´å¤šç›‘æ§ä¿¡æ¯
        current_lr = optimizer.param_groups[0]['lr']
        train_val_gap = val_loss_avg - train_loss_avg
        peak_memory = gpu_monitor.get_peak_memory()
        print(f"Epoch {epoch+1:2d}: Train={train_loss_avg:.6f} (Î¸:{train_theta_avg:.6f}, Ï†:{train_phi_avg:.6f}), "
              f"Val={val_loss_avg:.6f} (Î¸:{val_theta_avg:.6f}, Ï†:{val_phi_avg:.6f}), "
              f"Gap={train_val_gap:.6f}, LR={current_lr:.2e}, GPU={peak_memory:.1f}GB, Patience={patience_counter}/{current_early_stop_patience}")
        
        # æ—©åœå’Œæ¨¡å‹ä¿å­˜ - æ”¹è¿›ç­–ç•¥
        improvement = best_val_loss - val_loss_avg
        if improvement > min_improvement:  # åªæœ‰æ˜æ˜¾æ”¹è¿›æ‰é‡ç½®è®¡æ•°å™¨
            best_val_loss = val_loss_avg
            patience_counter = 0
            
            # ä¿å­˜æ¨¡å‹æ—¶éœ€è¦è€ƒè™‘DataParallel
            if is_multi_gpu:
                torch.save(model.module.state_dict(), 'best_beamforming_model_fixed.pth')
            else:
                torch.save(model.state_dict(), 'best_beamforming_model_fixed.pth')
            print(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Loss: {val_loss_avg:.6f}, æ”¹è¿›: {improvement:.6f})")
        else:
            patience_counter += 1
            
        if patience_counter >= current_early_stop_patience:
            print(f"æ—©åœè§¦å‘ï¼åœ¨epoch {epoch+1}åœæ­¢è®­ç»ƒ (patience: {patience_counter}/{current_early_stop_patience})")
            break
        
        # å®šæœŸæ˜¾å­˜æ¸…ç†
        if epoch % 10 == 0:
            optimize_memory_usage()
    
    print(f" è®­ç»ƒå®Œæˆï¼Œå³°å€¼æ˜¾å­˜ä½¿ç”¨: {gpu_monitor.get_peak_memory():.1f}GB")
    return train_losses, val_losses

def improved_loss_function(predictions, targets, loss_type='focal_huber'):
    """æ”¹è¿›çš„æŸå¤±å‡½æ•°ï¼Œé™ä½è§’åº¦é¢„æµ‹è¯¯å·®"""
    pred_angles = predictions  # [batch, 2] (theta, phi)
    target_theta, target_phi = targets
    
    # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç›®æ ‡
    target_theta_last = target_theta[:, -1]  # [batch]
    target_phi_last = target_phi[:, -1]      # [batch]
    
    if loss_type == 'focal_huber':
        # ç»„åˆFocal Losså’ŒHuber Lossçš„æ€æƒ³
        # è®¡ç®—åŸºç¡€è¯¯å·®
        theta_error = torch.abs(pred_angles[:, 0] - target_theta_last)
        phi_error = torch.abs(pred_angles[:, 1] - target_phi_last)
        
        # Focalæƒé‡ï¼šå¯¹éš¾æ ·æœ¬åŠ æƒ
        theta_focal_weight = torch.pow(theta_error + 1e-8, 0.5)  # å¹³æ–¹æ ¹æƒé‡
        phi_focal_weight = torch.pow(phi_error + 1e-8, 0.5)
        
        # HuberæŸå¤±
        theta_loss = F.huber_loss(pred_angles[:, 0], target_theta_last, delta=0.5, reduction='none')
        phi_loss = F.huber_loss(pred_angles[:, 1], target_phi_last, delta=0.5, reduction='none')
        
        # åº”ç”¨focalæƒé‡
        theta_loss = (theta_focal_weight * theta_loss).mean()
        phi_loss = (phi_focal_weight * phi_loss).mean()
        
    elif loss_type == 'adaptive_mse':
        # è‡ªé€‚åº”MSEæŸå¤±
        theta_loss = F.mse_loss(pred_angles[:, 0], target_theta_last)
        phi_loss = F.mse_loss(pred_angles[:, 1], target_phi_last)
        
        # åŠ¨æ€æƒé‡å¹³è¡¡
        theta_weight = 1.0 / (theta_loss.detach() + 1e-8)
        phi_weight = 1.0 / (phi_loss.detach() + 1e-8)
        
        total_weight = theta_weight + phi_weight
        theta_weight = theta_weight / total_weight
        phi_weight = phi_weight / total_weight
        
        theta_loss = theta_weight * theta_loss
        phi_loss = phi_weight * phi_loss
        
    else:
        # æ ‡å‡†HuberæŸå¤±
        theta_loss = F.huber_loss(pred_angles[:, 0], target_theta_last, delta=1.0)
        phi_loss = F.huber_loss(pred_angles[:, 1], target_phi_last, delta=1.0)
    
    total_loss = theta_loss + phi_loss
    
    # æ·»åŠ æ­£åˆ™åŒ–é¡¹
    l2_reg = 0.0
    for param in pred_angles.requires_grad_(True):
        if param.requires_grad:
            l2_reg += torch.norm(param)
    total_loss += 1e-6 * l2_reg
    
    # ç¡®ä¿æŸå¤±å€¼åœ¨åˆç†èŒƒå›´å†…
    total_loss = torch.clamp(total_loss, 0, 50)
    
    return total_loss, theta_loss, phi_loss

def create_original_model():
    """åˆ›å»ºåŸå§‹æ¨¡å‹ï¼ˆç”¨äºå¯¹æ¯”ï¼‰"""
    model = TransformerBeamformingNet(
        input_dim=256*256*2,
        d_model=512,
        nhead=8,
        num_layers=6,
        dropout=0.15
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ”§ åŸå§‹æ¨¡å‹åˆ›å»ºå®Œæˆ:")
    print(f"   â€¢ æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"   â€¢ æ¨¡å‹ç»´åº¦: 512")
    print(f"   â€¢ æ³¨æ„åŠ›å¤´æ•°: 8")
    print(f"   â€¢ Transformerå±‚æ•°: 6")
    
    return model

def test_model(model, test_loader, device='cuda'):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼Œæ”¯æŒå¤šGPU"""
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¢«DataParallelåŒ…è£…
    is_multi_gpu = isinstance(model, DataParallel)
    
    # å¦‚æœæ˜¯å¤šGPUæ¨¡å‹ï¼Œç¡®ä¿è®¾å¤‡æ­£ç¡®
    if is_multi_gpu:
        model.to(device)
    else:
        model.to(device)
    
    model.eval()
    
    all_predictions = []
    angle_errors = []
    
    # å¯ç”¨æ··åˆç²¾åº¦æ¨ç†ä»¥èŠ‚çœæ˜¾å­˜
    use_amp = torch.cuda.is_available() and device != 'cpu'
    
    with torch.no_grad():
        test_progress = tqdm(test_loader, desc="ğŸ§ª æµ‹è¯•è¿›åº¦")
        
        for H_input, theta_label, phi_label, H_complex in test_progress:
            try:
                H_input = H_input.to(device, non_blocking=True)
                theta_label = theta_label.to(device, non_blocking=True)
                phi_label = phi_label.to(device, non_blocking=True)
                
                # æ··åˆç²¾åº¦æ¨ç†
                if use_amp:
                    with torch.cuda.amp.autocast():
                        predictions = model(H_input)
                else:
                    predictions = model(H_input)
                
                # è½¬æ¢ä¸ºåº¦æ•°ï¼ˆåå½’ä¸€åŒ–ï¼‰
                pred_angles = predictions.cpu().numpy()
                pred_theta_norm = pred_angles[:, 0]  # [-1, 1]
                pred_phi_norm = pred_angles[:, 1]    # [-1, 1]
                
                # åå½’ä¸€åŒ–åˆ°åº¦æ•°ï¼ˆä¿®æ­£èŒƒå›´ï¼‰
                pred_theta_deg = pred_theta_norm * 90  # [-90, 90] å¯¹åº” [-1, 1]
                pred_phi_deg = pred_phi_norm * 180     # [-180, 180] å¯¹åº” [-1, 1]
                
                # ç›®æ ‡è§’åº¦ï¼ˆä½¿ç”¨æœ€åæ—¶é—´æ­¥ï¼‰
                target_theta_norm = theta_label[:, -1].cpu().numpy()
                target_phi_norm = phi_label[:, -1].cpu().numpy()
                
                target_theta_deg = target_theta_norm * 90
                target_phi_deg = target_phi_norm * 180
                
                # è®¡ç®—è§’åº¦è¯¯å·®
                theta_error = np.abs(pred_theta_deg - target_theta_deg)
                phi_error = np.abs(pred_phi_deg - target_phi_deg)
                
                # å¤„ç†phiè§’åº¦çš„å‘¨æœŸæ€§
                phi_error = np.minimum(phi_error, 360 - phi_error)
                
                total_error = theta_error + phi_error
                angle_errors.extend(total_error)
                
                for i in range(len(pred_angles)):
                    all_predictions.append({
                        'predicted_theta': pred_theta_deg[i],
                        'predicted_phi': pred_phi_deg[i],
                        'target_theta': target_theta_deg[i],
                        'target_phi': target_phi_deg[i],
                        'theta_error': theta_error[i],
                        'phi_error': phi_error[i],
                        'total_error': total_error[i]
                    })
                    
            except Exception as e:
                print(f"æµ‹è¯•æ‰¹æ¬¡é”™è¯¯: {e}")
                continue
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    if len(angle_errors) > 0:
        mean_error = np.mean(angle_errors)
        std_error = np.std(angle_errors)
        median_error = np.median(angle_errors)
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"å¹³å‡è§’åº¦è¯¯å·®: {mean_error:.2f}Â°")
        print(f"è§’åº¦è¯¯å·®æ ‡å‡†å·®: {std_error:.2f}Â°")
        print(f"è§’åº¦è¯¯å·®ä¸­ä½æ•°: {median_error:.2f}Â°")
        print(f"æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(all_predictions)}")
        
        if len(all_predictions) > 0:
            theta_errors = [p['theta_error'] for p in all_predictions]
            phi_errors = [p['phi_error'] for p in all_predictions]
            print(f"Î¸è¯¯å·®: {np.mean(theta_errors):.2f}Â° Â± {np.std(theta_errors):.2f}Â°")
            print(f"Ï†è¯¯å·®: {np.mean(phi_errors):.2f}Â° Â± {np.std(phi_errors):.2f}Â°")
    else:
        print("æ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»“æœ")
    
    return all_predictions

def setup_distributed_training():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ["RANK"])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        
        dist.init_process_group(backend="nccl", rank=rank, world_size=world_size)
        torch.cuda.set_device(local_rank)
        
        return rank, world_size, local_rank
    else:
        return None, None, None

def cleanup_distributed():
    """æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if dist.is_initialized():
        dist.destroy_process_group()

def get_available_gpus():
    """è·å–å¯ç”¨çš„GPUä¿¡æ¯"""
    if not torch.cuda.is_available():
        return []
    
    gpu_count = torch.cuda.device_count()
    gpu_info = []
    
    for i in range(gpu_count):
        gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3  # GB
        gpu_name = torch.cuda.get_device_properties(i).name
        gpu_info.append({
            'id': i,
            'name': gpu_name,
            'memory_gb': gpu_memory
        })
    
    return gpu_info

def setup_multi_gpu_model(model, device_ids=None):
    """è®¾ç½®å¤šGPUæ¨¡å‹"""
    if not torch.cuda.is_available():
        print("âŒ CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        return model, 'cpu'
    
    gpu_info = get_available_gpus()
    gpu_count = len(gpu_info)
    
    print(f"ğŸ–¥ï¸  æ£€æµ‹åˆ° {gpu_count} å¼ GPU:")
    for gpu in gpu_info:
        print(f"   â€¢ GPU {gpu['id']}: {gpu['name']} ({gpu['memory_gb']:.1f}GB)")
    
    if gpu_count >= 2:
        if device_ids is None:
            device_ids = list(range(gpu_count))
        
        print(f"ğŸš€ å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼Œä½¿ç”¨GPU: {device_ids}")
        
        # å°†æ¨¡å‹ç§»åˆ°ä¸»GPU
        model = model.cuda(device_ids[0])
        
        # ä½¿ç”¨DataParallelè¿›è¡Œå¤šGPUè®­ç»ƒ
        model = DataParallel(model, device_ids=device_ids)
        
        # è®¾ç½®ä¸»è®¾å¤‡
        device = f'cuda:{device_ids[0]}'
        
        # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥èŠ‚çœæ˜¾å­˜
        torch.backends.cudnn.benchmark = True
        
        return model, device
    
    elif gpu_count == 1:
        print("ğŸ“± ä½¿ç”¨å•GPUè®­ç»ƒ")
        device = 'cuda:0'
        model = model.cuda()
        return model, device
    
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        return model, 'cpu'

def optimize_memory_usage():
    """ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨"""
    if torch.cuda.is_available():
        # æ¸…ç©ºGPUç¼“å­˜
        torch.cuda.empty_cache()
        
        # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
        torch.cuda.memory._set_allocator_settings('expandable_segments:True')
        
        # æ‰“å°å½“å‰æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            cached = torch.cuda.memory_reserved(i) / 1024**3
            total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"GPU {i} æ˜¾å­˜: {allocated:.1f}GB å·²åˆ†é…, {cached:.1f}GB å·²ç¼“å­˜, {total:.1f}GB æ€»è®¡")

class GPUMonitor:
    """GPUæ˜¾å­˜ç›‘æ§å™¨"""
    def __init__(self):
        self.peak_memory = 0
        
    def update(self):
        if torch.cuda.is_available():
            current_memory = torch.cuda.max_memory_allocated() / 1024**3
            if current_memory > self.peak_memory:
                self.peak_memory = current_memory
    
    def get_peak_memory(self):
        return self.peak_memory
    
    def reset(self):
        if torch.cuda.is_available():
            torch.cuda.reset_peak_memory_stats()
        self.peak_memory = 0

def main():
    """ä¸»å‡½æ•° - æ”¯æŒæ¨¡å‹é€‰æ‹©å’Œå¤šGPUè®­ç»ƒ"""
    warnings.filterwarnings('ignore', category=UserWarning)
    
    # æ£€æµ‹å¹¶æ˜¾ç¤ºGPUä¿¡æ¯
    gpu_info = get_available_gpus()
    gpu_count = len(gpu_info)
    
    print(f"ğŸ–¥ï¸  GPUæ£€æµ‹ç»“æœ:")
    if gpu_count == 0:
        print("   âŒ æœªæ£€æµ‹åˆ°CUDA GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        device = 'cpu'
        use_multi_gpu = False
    else:
        print(f"   âœ… æ£€æµ‹åˆ° {gpu_count} å¼ GPU:")
        total_memory = 0
        for gpu in gpu_info:
            print(f"      â€¢ GPU {gpu['id']}: {gpu['name']} ({gpu['memory_gb']:.1f}GB)")
            total_memory += gpu['memory_gb']
        print(f"   ğŸ“Š æ€»æ˜¾å­˜å®¹é‡: {total_memory:.1f}GB")
        
        device = 'cuda'
        use_multi_gpu = gpu_count > 1
        
        if use_multi_gpu:
            print(f"   ğŸš€ å°†å¯ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒï¼Œä½¿ç”¨ {gpu_count} å¼ GPU")
        else:
            print(f"   ï¿½ å°†ä½¿ç”¨å•GPUè®­ç»ƒ")
    
    # ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
    if device == 'cuda':
        optimize_memory_usage()
    
    # ç”¨æˆ·é€‰æ‹©æ¨¡å‹ç±»å‹
    print("\nğŸ¤– è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:")
    print("1. åŸå§‹æ¨¡å‹ (è¾ƒå¿«è®­ç»ƒï¼Œé€‚ä¸­ç²¾åº¦)")
    print("2. å¢å¼ºæ¨¡å‹ (è¾ƒæ…¢è®­ç»ƒï¼Œæ›´é«˜ç²¾åº¦)")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2ï¼Œé»˜è®¤ä¸º 2): ").strip()
    use_enhanced = choice != "1"
    
    if use_enhanced:
        print("âœ… é€‰æ‹©äº†å¢å¼ºæ¨¡å‹ - å°†è·å¾—æ›´é«˜ç²¾åº¦ä½†éœ€è¦æ›´é•¿è®­ç»ƒæ—¶é—´")
        model_save_name = 'best_ultra_beamforming_model.pth'
        results_file_name = 'enhanced_training_results.png'
    else:
        print("âœ… é€‰æ‹©äº†åŸå§‹æ¨¡å‹ - è®­ç»ƒé€Ÿåº¦è¾ƒå¿«")
        model_save_name = 'best_beamforming_model_fixed.pth'
        results_file_name = 'original_training_results.png'
    
    # æ•°æ®è·¯å¾„
    channel_folder = "samples_data/channel_data_opt_20250702_143327"
    angle_folder = "samples_data/angle_data_opt_20250702_143327"
    
    print("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = BeamformingDataset(channel_folder, angle_folder)
    
    # æŒ‰è¦æ±‚åˆ’åˆ†æ•°æ®é›†ï¼š800è®­ç»ƒï¼Œ200æµ‹è¯•
    total_samples = len(dataset)
    train_size = 800
    test_size = total_samples - train_size
    
    indices = list(range(total_samples))
    np.random.seed(42)  # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
    np.random.shuffle(indices)
    
    train_indices = indices[:train_size]
    test_indices = indices[train_size:]
    
    # ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†éªŒè¯é›† - å¢åŠ éªŒè¯é›†å¤§å°æé«˜ç¨³å®šæ€§
    val_size = int(train_size * 0.25)  # 25%ä½œä¸ºéªŒè¯é›†ï¼Œæé«˜ç¨³å®šæ€§
    train_final_indices = train_indices[val_size:]
    val_indices = train_indices[:val_size]
    
    print(f"æ•°æ®é›†åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_final_indices)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_indices)} æ ·æœ¬") 
    print(f"  æµ‹è¯•é›†: {len(test_indices)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®å­é›†
    train_dataset = torch.utils.data.Subset(dataset, train_final_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    test_dataset = torch.utils.data.Subset(dataset, test_indices)
    
    # æ ¹æ®GPUæ•°é‡è°ƒæ•´æ‰¹æ¬¡å¤§å°
    if gpu_count >= 2:
        batch_size = 8  # åŒGPUå¯ä»¥ä½¿ç”¨æ›´å¤§æ‰¹æ¬¡
        num_workers = 8  # å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
    elif gpu_count == 1:
        batch_size = 6  # å•GPUé€‚ä¸­æ‰¹æ¬¡
        num_workers = 4
    else:
        batch_size = 2  # CPUè®­ç»ƒä½¿ç”¨å°æ‰¹æ¬¡
        num_workers = 2
    
    print(f"ğŸ”§ è®­ç»ƒé…ç½®:")
    print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   â€¢ æ•°æ®åŠ è½½è¿›ç¨‹: {num_workers}")
    print(f"   â€¢ å¤šGPUè®­ç»ƒ: {'å¯ç”¨' if use_multi_gpu else 'ç¦ç”¨'}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers, 
        pin_memory=(device=='cuda'), 
        drop_last=True,
        persistent_workers=True if num_workers > 0 else False
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers, 
        pin_memory=(device=='cuda'),
        persistent_workers=True if num_workers > 0 else False
    )
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers, 
        pin_memory=(device=='cuda'),
        persistent_workers=True if num_workers > 0 else False
    )
    
    # åˆ›å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»º{'å¢å¼º' if use_enhanced else 'åŸå§‹'}æ¨¡å‹...")
    if use_enhanced:
        model = create_enhanced_model()
        
        # è®­ç»ƒæ¨¡å‹
        print("\nğŸš€ å¼€å§‹å¢å¼ºæ¨¡å‹è®­ç»ƒ...")
        train_losses, val_losses = enhanced_train_model(
            model, train_loader, val_loader, 
            num_epochs=200,  # å¢åŠ è®­ç»ƒè½®æ•°
            lr=1e-4,         # ä¿å®ˆçš„å­¦ä¹ ç‡
            device=device,
            use_multi_gpu=use_multi_gpu
        )
    else:
        model = create_original_model()
        
        # è®­ç»ƒæ¨¡å‹
        print("\nğŸš€ å¼€å§‹åŸå§‹æ¨¡å‹è®­ç»ƒ...")
        train_losses, val_losses = train_model(
            model, train_loader, val_loader, 
            num_epochs=150,
            lr=3e-4,
            device=device,
            use_multi_gpu=use_multi_gpu
        )
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if os.path.exists(model_save_name):
        # å¤„ç†å¤šGPUæ¨¡å‹çš„çŠ¶æ€å­—å…¸åŠ è½½
        state_dict = torch.load(model_save_name, map_location=device)
        
        # å¦‚æœå½“å‰æ¨¡å‹æ˜¯DataParallelä½†ä¿å­˜çš„ä¸æ˜¯ï¼Œéœ€è¦æ·»åŠ moduleå‰ç¼€
        if isinstance(model, DataParallel) and not any(k.startswith('module.') for k in state_dict.keys()):
            state_dict = {f'module.{k}': v for k, v in state_dict.items()}
        # å¦‚æœå½“å‰æ¨¡å‹ä¸æ˜¯DataParallelä½†ä¿å­˜çš„æ˜¯ï¼Œéœ€è¦ç§»é™¤moduleå‰ç¼€
        elif not isinstance(model, DataParallel) and any(k.startswith('module.') for k in state_dict.keys()):
            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        
        model.load_state_dict(state_dict)
        print(f"âœ… åŠ è½½æœ€ä½³{'å¢å¼º' if use_enhanced else 'åŸå§‹'}æ¨¡å‹å®Œæˆ")
    
    # æµ‹è¯•æ¨¡å‹
    print("\nğŸ§ª å¼€å§‹æµ‹è¯•...")
    predictions = test_model(model, test_loader, device=device)
    
    # ç»˜åˆ¶ç»“æœ
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # è®­ç»ƒæŸå¤±æ›²çº¿
    axes[0, 0].plot(train_losses, label='Training Loss', alpha=0.8)
    axes[0, 0].plot(val_losses, label='Validation Loss', alpha=0.8)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('Training Progress')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].set_yscale('log')
    
    # è§’åº¦é¢„æµ‹æ•£ç‚¹å›¾
    if len(predictions) > 0:
        pred_theta = [p['predicted_theta'] for p in predictions]
        target_theta = [p['target_theta'] for p in predictions]
        pred_phi = [p['predicted_phi'] for p in predictions]
        target_phi = [p['target_phi'] for p in predictions]
        
        # Î¸è§’åº¦é¢„æµ‹
        axes[0, 1].scatter(target_theta, pred_theta, alpha=0.6, s=20)
        min_theta = min(min(target_theta), min(pred_theta))
        max_theta = max(max(target_theta), max(pred_theta))
        axes[0, 1].plot([min_theta, max_theta], [min_theta, max_theta], 'r--', label='Perfect')
        axes[0, 1].set_xlabel('True Î¸ (degrees)')
        axes[0, 1].set_ylabel('Predicted Î¸ (degrees)')
        axes[0, 1].set_title('Î¸ Angle Prediction')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Ï†è§’åº¦é¢„æµ‹
        axes[1, 0].scatter(target_phi, pred_phi, alpha=0.6, s=20)
        min_phi = min(min(target_phi), min(pred_phi))
        max_phi = max(max(target_phi), max(pred_phi))
        axes[1, 0].plot([min_phi, max_phi], [min_phi, max_phi], 'r--', label='Perfect')
        axes[1, 0].set_xlabel('True Ï† (degrees)')
        axes[1, 0].set_ylabel('Predicted Ï† (degrees)')
        axes[1, 0].set_title('Ï† Angle Prediction')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # è¯¯å·®åˆ†å¸ƒ
        errors = [p['total_error'] for p in predictions]
        axes[1, 1].hist(errors, bins=30, alpha=0.7, edgecolor='black')
        axes[1, 1].axvline(np.mean(errors), color='red', linestyle='--', label=f'Mean: {np.mean(errors):.1f}Â°')
        axes[1, 1].set_xlabel('Total Angle Error (degrees)')
        axes[1, 1].set_ylabel('Frequency')
        axes[1, 1].set_title('Error Distribution')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(results_file_name, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“ˆ {'å¢å¼º' if use_enhanced else 'åŸå§‹'}æ¨¡å‹è®­ç»ƒç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º '{results_file_name}'")
    
    # æ‰“å°è®­ç»ƒæ€»ç»“
    print(f"\nğŸ“‹ {'å¢å¼º' if use_enhanced else 'åŸå§‹'}æ¨¡å‹è®­ç»ƒæ€»ç»“:")
    if train_losses:
        print(f"â€¢ æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_losses[-1]:.6f}")
        print(f"â€¢ æœ€ç»ˆéªŒè¯æŸå¤±: {val_losses[-1]:.6f}")
        print(f"â€¢ æ€»è®­ç»ƒè½®æ•°: {len(train_losses)}")
        print(f"â€¢ æŸå¤±æ”¹å–„: {((train_losses[0] - train_losses[-1]) / train_losses[0] * 100):.1f}%")
        
        # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡æ—¶è¦è€ƒè™‘DataParallel
        if isinstance(model, DataParallel):
            param_count = sum(p.numel() for p in model.module.parameters())
        else:
            param_count = sum(p.numel() for p in model.parameters())
        print(f"â€¢ æ¨¡å‹å¤æ‚åº¦: ~{param_count:,} å‚æ•°")
        print(f"â€¢ å¤šGPUè®­ç»ƒ: {'æ˜¯' if use_multi_gpu else 'å¦'}")
        print(f"â€¢ GPUæ•°é‡: {gpu_count}")
    
    # æœ€ç»ˆæ˜¾å­˜æ¸…ç†
    if device == 'cuda':
        torch.cuda.empty_cache()
        print(f"â€¢ æœ€ç»ˆæ˜¾å­˜æ¸…ç†å®Œæˆ")
    
    return model, predictions

if __name__ == "__main__":
    main()